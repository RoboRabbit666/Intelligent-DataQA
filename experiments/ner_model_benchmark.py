# NERæ¨¡å‹æ€§èƒ½åŸºå‡†æµ‹è¯•
# æ–‡ä»¶åï¼šner_model_benchmark.py

import spacy
import time
import json
from typing import Dict, List, Tuple
import pandas as pd

def create_test_corpus():
    """åˆ›å»ºæœŸè´§äº¤æ˜“é¢†åŸŸçš„æµ‹è¯•è¯­æ–™"""
    
    test_texts = [
        "è‹¹æœæœŸè´§åœ¨éƒ‘å·å•†å“äº¤æ˜“æ‰€äº¤æ˜“ï¼Œåæ³°æœŸè´§å…¬å¸å‚ä¸å…¶ä¸­",
        "ä¸Šæµ·æœŸè´§äº¤æ˜“æ‰€çš„é“œæœŸè´§ä»·æ ¼ä¸Šæ¶¨ï¼Œä¸­ä¿¡æœŸè´§å‘å¸ƒç ”ç©¶æŠ¥å‘Š",
        "å¤§è¿å•†å“äº¤æ˜“æ‰€æ¨å‡ºæ–°çš„è±†ç²•æœŸè´§åˆçº¦ï¼Œæ°¸å®‰æœŸè´§ç§¯æå‚ä¸äº¤æ˜“",
        "éƒ‘å•†æ‰€ç™½ç³–æœŸè´§ä¸»åŠ›åˆçº¦æ”¶ç›˜ä»·æ ¼ä¸º5200å…ƒ/å¨",
        "shfeèºçº¹é’¢æœŸè´§ä»Šæ—¥æˆäº¤æ´»è·ƒï¼Œåæ³°æœŸè´§ç ”ç©¶æ‰€å‘å¸ƒçœ‹æ¶¨æŠ¥å‘Š",
        "czceæ£‰èŠ±æœŸè´§CF2024åˆçº¦äº¤å‰²æœˆä¸´è¿‘",
        "ä¸­å›½é‡‘èæœŸè´§äº¤æ˜“æ‰€è‚¡æŒ‡æœŸè´§IF2024åˆçº¦æ³¢åŠ¨åŠ å‰§",
        "æ°¸å®‰æœŸè´§ã€æµ·é€šæœŸè´§ã€ç”³é“¶ä¸‡å›½æœŸè´§ä¸‰å®¶å…¬å¸æŒä»“æ’åå‰ä¸‰",
        "çº¢æ£jræœŸè´§åœ¨éƒ‘å·å•†å“äº¤æ˜“æ‰€ä¸Šå¸‚ä»¥æ¥è¡¨ç°æ´»è·ƒ",
        "dceç‰ç±³æœŸè´§C2024åˆçº¦ä»·æ ¼çªç ´å‰æœŸé«˜ç‚¹"
    ]
    
    return test_texts

def benchmark_model_configurations():
    """åŸºå‡†æµ‹è¯•ä¸åŒæ¨¡å‹é…ç½®"""
    
    # é…ç½®å®šä¹‰
    configurations = {
        "md_full": {
            "model": "zh_core_web_md",
            "exclude": [],
            "description": "ä¸­å‹æ¨¡å‹å®Œæ•´é…ç½®"
        },
        "trf_ner_only": {
            "model": "zh_core_web_trf", 
            "exclude": ["parser", "tagger", "lemmatizer", "attribute_ruler"],
            "description": "å¤§æ¨¡å‹ä»…NER"
        },
        "trf_ner_pos": {
            "model": "zh_core_web_trf",
            "exclude": ["parser", "lemmatizer", "attribute_ruler"], 
            "description": "å¤§æ¨¡å‹NER+è¯æ€§"
        },
        "trf_full": {
            "model": "zh_core_web_trf",
            "exclude": [],
            "description": "å¤§æ¨¡å‹å®Œæ•´é…ç½®"
        }
    }
    
    test_texts = create_test_corpus()
    results = {}
    
    print("ğŸ”¬ å¼€å§‹NERæ¨¡å‹æ€§èƒ½åŸºå‡†æµ‹è¯•")
    print("=" * 60)
    
    for config_name, config in configurations.items():
        print(f"\nğŸ“Š æµ‹è¯•é…ç½®: {config['description']}")
        print("-" * 40)
        
        try:
            # åŠ è½½æ¨¡å‹
            start_load = time.time()
            nlp = spacy.load(config["model"], exclude=config["exclude"])
            load_time = time.time() - start_load
            
            print(f"æ¨¡å‹åŠ è½½æ—¶é—´: {load_time:.2f}ç§’")
            print(f"æ’é™¤ç»„ä»¶: {config['exclude']}")
            print(f"æ¿€æ´»ç®¡é“: {nlp.pipe_names}")
            
            # é¢„çƒ­æ¨¡å‹
            warmup_text = test_texts[0]
            for _ in range(3):
                _ = nlp(warmup_text)
            
            # æ€§èƒ½æµ‹è¯•
            start_time = time.time()
            all_entities = []
            
            for text in test_texts:
                doc = nlp(text)
                entities = [(ent.text, ent.label_, ent.start_char, ent.end_char) 
                           for ent in doc.ents]
                all_entities.append({
                    "text": text,
                    "entities": entities,
                    "entity_count": len(entities)
                })
            
            total_time = time.time() - start_time
            avg_time = total_time / len(test_texts)
            
            # ç»Ÿè®¡ç»“æœ
            total_entities = sum(item["entity_count"] for item in all_entities)
            
            results[config_name] = {
                "model": config["model"],
                "description": config["description"],
                "excluded_components": config["exclude"],
                "active_pipes": nlp.pipe_names,
                "load_time": load_time,
                "total_processing_time": total_time,
                "avg_time_per_text": avg_time,
                "texts_per_second": len(test_texts) / total_time,
                "total_entities_found": total_entities,
                "avg_entities_per_text": total_entities / len(test_texts),
                "detailed_results": all_entities[:3]  # åªä¿å­˜å‰3ä¸ªè¯¦ç»†ç»“æœ
            }
            
            print(f"âœ… å¤„ç†{len(test_texts)}ä¸ªæ–‡æœ¬ç”¨æ—¶: {total_time:.3f}ç§’")
            print(f"âš¡ å¹³å‡æ¯æ–‡æœ¬: {avg_time:.4f}ç§’")
            print(f"ğŸš€ å¤„ç†é€Ÿåº¦: {len(test_texts)/total_time:.1f} æ–‡æœ¬/ç§’")
            print(f"ğŸ¯ å‘ç°å®ä½“æ€»æ•°: {total_entities}")
            print(f"ğŸ“ æ ·ä¾‹å®ä½“: {all_entities[0]['entities']}")
            
        except OSError as e:
            print(f"âŒ æ— æ³•åŠ è½½æ¨¡å‹ {config['model']}: {e}")
            results[config_name] = None
        except Exception as e:
            print(f"âŒ æµ‹è¯•è¿‡ç¨‹å‡ºé”™: {e}")
            results[config_name] = None
    
    return results

def analyze_ner_quality(results):
    """åˆ†æNERè´¨é‡"""
    
    print(f"\nğŸ“ˆ NERè´¨é‡åˆ†æ")
    print("=" * 60)
    
    # æœŸè´§é¢†åŸŸå…³é”®å®ä½“ç±»å‹
    expected_entity_types = {
        "ORG": ["åæ³°æœŸè´§", "ä¸­ä¿¡æœŸè´§", "æ°¸å®‰æœŸè´§", "éƒ‘å·å•†å“äº¤æ˜“æ‰€", "ä¸Šæµ·æœŸè´§äº¤æ˜“æ‰€"],
        "PRODUCT": ["è‹¹æœ", "é“œ", "è±†ç²•", "ç™½ç³–", "èºçº¹é’¢"],
        "EXCHANGE": ["éƒ‘å•†æ‰€", "shfe", "czce", "dce"]
    }
    
    for config_name, result in results.items():
        if result is None:
            continue
            
        print(f"\nğŸ” {result['description']} - å®ä½“è´¨é‡åˆ†æ:")
        
        found_entities = {}
        for item in result["detailed_results"]:
            for entity_text, entity_label, start, end in item["entities"]:
                if entity_label not in found_entities:
                    found_entities[entity_label] = []
                found_entities[entity_label].append(entity_text)
        
        print(f"  å‘ç°çš„å®ä½“ç±»å‹: {list(found_entities.keys())}")
        for label, entities in found_entities.items():
            unique_entities = list(set(entities))
            print(f"    {label}: {unique_entities[:5]}")  # æ˜¾ç¤ºå‰5ä¸ª

def create_performance_comparison(results):
    """åˆ›å»ºæ€§èƒ½å¯¹æ¯”è¡¨"""
    
    print(f"\nğŸ“Š æ€§èƒ½å¯¹æ¯”æ€»ç»“")
    print("=" * 80)
    
    # åˆ›å»ºå¯¹æ¯”è¡¨
    comparison_data = []
    
    for config_name, result in results.items():
        if result is None:
            continue
            
        comparison_data.append({
            "é…ç½®": result["description"],
            "æ¨¡å‹å¤§å°": "74MB" if "md" in config_name else "396MB",
            "åŠ è½½æ—¶é—´(ç§’)": f"{result['load_time']:.2f}",
            "å¤„ç†é€Ÿåº¦(æ–‡æœ¬/ç§’)": f"{result['texts_per_second']:.1f}",
            "å¹³å‡å»¶è¿Ÿ(æ¯«ç§’)": f"{result['avg_time_per_text']*1000:.1f}",
            "å‘ç°å®ä½“æ•°": result['total_entities_found'],
            "ç›¸å¯¹é€Ÿåº¦": "åŸºå‡†" if "md_full" in config_name else ""
        })
    
    # è®¡ç®—ç›¸å¯¹é€Ÿåº¦
    if comparison_data:
        baseline_speed = None
        for item in comparison_data:
            if "å°æ¨¡å‹" in item["é…ç½®"]:
                baseline_speed = float(item["å¤„ç†é€Ÿåº¦(æ–‡æœ¬/ç§’)"])
                break
        
        if baseline_speed:
            for item in comparison_data:
                current_speed = float(item["å¤„ç†é€Ÿåº¦(æ–‡æœ¬/ç§’)"])
                if item["ç›¸å¯¹é€Ÿåº¦"] != "åŸºå‡†":
                    ratio = current_speed / baseline_speed
                    item["ç›¸å¯¹é€Ÿåº¦"] = f"{ratio:.2f}x"
    
    # æ‰“å°è¡¨æ ¼
    if comparison_data:
        df = pd.DataFrame(comparison_data)
        print(df.to_string(index=False))

def save_benchmark_results(results):
    """ä¿å­˜åŸºå‡†æµ‹è¯•ç»“æœ"""
    
    # æ¸…ç†ç»“æœä»¥ä¾¿JSONåºåˆ—åŒ–
    clean_results = {}
    for config_name, result in results.items():
        if result is not None:
            clean_results[config_name] = {
                k: v for k, v in result.items() 
                if k != "detailed_results"  # è¯¦ç»†ç»“æœå¤ªå¤§ï¼Œä¸ä¿å­˜
            }
    
    # ä¿å­˜åˆ°æ–‡ä»¶
    with open("ner_benchmark_results.json", "w", encoding="utf-8") as f:
        json.dump(clean_results, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ åŸºå‡†æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ° ner_benchmark_results.json")

def recommend_configuration(results):
    """åŸºäºæµ‹è¯•ç»“æœæ¨èé…ç½®"""
    
    print(f"\nğŸ¯ é…ç½®æ¨è")
    print("=" * 60)
    
    valid_results = {k: v for k, v in results.items() if v is not None}
    
    if not valid_results:
        print("âŒ æ²¡æœ‰å¯ç”¨çš„æµ‹è¯•ç»“æœ")
        return
    
    # åˆ†æå„é¡¹æŒ‡æ ‡
    fastest_config = min(valid_results.items(), 
                        key=lambda x: x[1]["avg_time_per_text"])
    most_entities = max(valid_results.items(), 
                       key=lambda x: x[1]["total_entities_found"])
    
    print(f"ğŸš€ é€Ÿåº¦æœ€å¿«: {fastest_config[1]['description']}")
    print(f"   å¹³å‡å»¶è¿Ÿ: {fastest_config[1]['avg_time_per_text']*1000:.1f}æ¯«ç§’")
    
    print(f"\nğŸ¯ å®ä½“æœ€å¤š: {most_entities[1]['description']}")
    print(f"   å‘ç°å®ä½“: {most_entities[1]['total_entities_found']}ä¸ª")
    
    # ç»¼åˆæ¨è
    print(f"\nğŸ’¡ ç»¼åˆæ¨è:")
    print(f"   å¯¹äºæ‚¨çš„DataQAé¡¹ç›®ï¼Œå»ºè®®ä½¿ç”¨excludeå‚æ•°:")
    print(f"   ğŸ“ˆ é«˜å‡†ç¡®ç‡éœ€æ±‚: zh_core_web_trf exclude=['parser', 'lemmatizer', 'attribute_ruler']")
    print(f"   âš¡ é«˜é€Ÿåº¦éœ€æ±‚: zh_core_web_trf exclude=['parser', 'tagger', 'lemmatizer', 'attribute_ruler']")
    print(f"   ğŸ’¾ å¹³è¡¡é€‰æ‹©: zh_core_web_md (å®Œæ•´é…ç½®ï¼Œ74MBï¼ŒNER F-score: 0.70)")
    print(f"   ğŸ¯ æœ€ä½³æ€§èƒ½: zh_core_web_trf (NER F-score: 0.74)")

def main():
    """ä¸»å‡½æ•°"""
    
    print("ğŸš€ NERæ¨¡å‹é…ç½®åŸºå‡†æµ‹è¯•")
    print("=" * 60)
    print("è¿™ä¸ªæµ‹è¯•å°†å¸®åŠ©æ‚¨é€‰æ‹©æœ€é€‚åˆçš„spaCyé…ç½®")
    print("åŒ…æ‹¬å‡†ç¡®ç‡ã€é€Ÿåº¦å’Œèµ„æºä½¿ç”¨çš„æƒè¡¡åˆ†æ\n")
    
    # è¿è¡ŒåŸºå‡†æµ‹è¯•
    results = benchmark_model_configurations()
    
    # åˆ†æç»“æœ
    analyze_ner_quality(results)
    create_performance_comparison(results)
    recommend_configuration(results)
    
    # ä¿å­˜ç»“æœ
    save_benchmark_results(results)
    
    print(f"\nğŸ‰ åŸºå‡†æµ‹è¯•å®Œæˆ!")
    print(f"åŸºäºæµ‹è¯•ç»“æœï¼Œæ‚¨å¯ä»¥é€‰æ‹©æœ€é€‚åˆçš„æ¨¡å‹é…ç½®")
    print(f"å»ºè®®ä½¿ç”¨excludeå‚æ•°æ¥å®Œå…¨æ’é™¤ä¸éœ€è¦çš„ç»„ä»¶ï¼ŒèŠ‚çœå†…å­˜å’Œæé«˜æ€§èƒ½")
    print(f"å»ºè®®å…ˆä»æ¨èé…ç½®å¼€å§‹ï¼Œç„¶åæ ¹æ®å®é™…ä½¿ç”¨æƒ…å†µè°ƒæ•´")

if __name__ == "__main__":
    main()
