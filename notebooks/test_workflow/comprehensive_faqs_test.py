# -*- coding: utf-8 -*-
"""
è¶…ç®€åŒ–ç‰ˆ252é—®é¢˜è‡ªåŠ¨åŒ–æµ‹è¯• - æ··åˆç­–ç•¥SQLæ¯”è¾ƒ
ä¿ç•™æ ¸å¿ƒåŠŸèƒ½ï¼Œå¤§å¹…ç®€åŒ–ä»£ç 
"""

import re
import json
from pathlib import Path
from datetime import datetime


def load_all_questions():
    """åŠ è½½252ä¸ªæµ‹è¯•é—®é¢˜"""
    print("ğŸ” åŠ è½½æµ‹è¯•é—®é¢˜...")
    
    tables_dir = Path("../test_data/tables")
    if not tables_dir.exists():
        tables_dir = Path("test_data/tables")
    
    questions = []
    question_id = 1
    
    for table_dir in tables_dir.iterdir():
        if not table_dir.is_dir():
            continue
            
        for sql_file in table_dir.glob("*sql*çŸ¥è¯†åº“.txt"):
            with open(sql_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # ç®€å•æ­£åˆ™è§£æ
            matches = re.findall(r'é—®é¢˜[:ï¼š](.*?)\n(?:--.*?\n)*((?:WITH|SELECT).*?)(?=\n\né—®é¢˜[:ï¼š]|\n\n$|$)', 
                               content, re.DOTALL | re.IGNORECASE)
            
            for question_text, sql_text in matches:
                questions.append({
                    'id': question_id,
                    'question': question_text.strip(),
                    'expected_sql': sql_text.strip(),
                    'table_name': table_dir.name
                })
                question_id += 1
    
    print(f"ğŸ“Š åŠ è½½äº† {len(questions)} ä¸ªé—®é¢˜")
    return questions


def simple_sql_compare(expected, actual):
    """
    ç®€åŒ–ç‰ˆæ··åˆç­–ç•¥SQLæ¯”è¾ƒ
    è¿”å›: (æ˜¯å¦åŒ¹é…, åŒ¹é…ç±»å‹)
    """
    if not expected or not actual:
        return False, "empty"
    
    # ç®€å•æ ‡å‡†åŒ–
    def normalize(sql):
        sql = re.sub(r'--.*?\n', '\n', sql)  # å»æ³¨é‡Š
        sql = re.sub(r'\s+', ' ', sql.strip().upper())  # æ ‡å‡†åŒ–ç©ºç™½å’Œå¤§å°å†™
        return sql.rstrip(';')
    
    norm_expected = normalize(expected)
    norm_actual = normalize(actual)
    
    # å®Œå…¨åŒ¹é…
    if norm_expected == norm_actual:
        return True, "exact"
    
    # å…³é”®è¯åŒ¹é…ï¼ˆç®€åŒ–è¯­ä¹‰æ£€æŸ¥ï¼‰
    def extract_keywords(sql):
        # æå–ä¸»è¦SQLç»„ä»¶
        keywords = []
        keywords.extend(re.findall(r'SELECT\s+(.*?)\s+FROM', sql))
        keywords.extend(re.findall(r'FROM\s+([^\s\(]+)', sql))
        keywords.extend(re.findall(r'WHERE\s+(.*?)(?:\s+GROUP|\s+ORDER|$)', sql))
        return ' '.join(keywords)
    
    expected_keywords = extract_keywords(norm_expected)
    actual_keywords = extract_keywords(norm_actual)
    
    # ç®€å•ç›¸ä¼¼åº¦æ£€æŸ¥
    if expected_keywords and actual_keywords:
        common_words = len(set(expected_keywords.split()) & set(actual_keywords.split()))
        total_words = len(set(expected_keywords.split()) | set(actual_keywords.split()))
        similarity = common_words / total_words if total_words > 0 else 0
        
        if similarity >= 0.7:  # 70%å…³é”®è¯åŒ¹é…
            return True, "semantic"
    
    return False, "no_match"


def extract_sql_from_response(response):
    """ä»å“åº”ä¸­æå–SQL"""
    if not response or not response.choices:
        return ""
    
    content = response.choices[0].message.content
    
    # æå–SQLä»£ç å—
    sql_match = re.search(r"```(?:sql)?\s*\n(.*?)\n```", content, re.DOTALL | re.IGNORECASE)
    if sql_match:
        return sql_match.group(1).strip()
    
    # ç›´æ¥æŸ¥æ‰¾SQLè¯­å¥
    sql_match = re.search(r'\b(WITH|SELECT).*', content, re.DOTALL | re.IGNORECASE)
    if sql_match:
        return sql_match.group(0).strip()
    
    return content.strip()


def test_single_question(question, workflow):
    """æµ‹è¯•å•ä¸ªé—®é¢˜"""
    try:
        # æ„é€ è¯·æ±‚
        messages = [ChatMessage(role="user", content=question['question'])]
        request = DataQACompletionRequest(
            messages=messages,
            model="test",
            created=int(datetime.now().timestamp()),
            follow_up_num=0,
            knowledge_base_ids=["3cc33ed2-21fb-4452-9e10-528867bd5f99"],
            use_reranker=True
        )
        
        # æ‰§è¡Œå·¥ä½œæµ
        response = workflow.do_generate(request=request, enable_follow_up=False, thinking=False)
        
        # æå–ç»“æœ
        actual_sql = extract_sql_from_response(response)
        is_faq_path = response.model == "faq"
        is_match, match_type = simple_sql_compare(question['expected_sql'], actual_sql)
        
        return {
            'id': question['id'],
            'question': question['question'],
            'table': question['table_name'],
            'expected_sql': question['expected_sql'],
            'actual_sql': actual_sql,
            'is_match': is_match,
            'match_type': match_type,
            'is_faq': is_faq_path,
            'error': None
        }
        
    except Exception as e:
        return {
            'id': question['id'],
            'question': question['question'],
            'table': question['table_name'],
            'expected_sql': question['expected_sql'],
            'actual_sql': "",
            'is_match': False,
            'match_type': "error",
            'is_faq': False,
            'error': str(e)
        }


def run_all_tests(workflow, max_questions=None):
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("ğŸš€ å¼€å§‹æ‰¹é‡æµ‹è¯•...")
    
    # åŠ è½½é—®é¢˜
    questions = load_all_questions()
    if max_questions:
        questions = questions[:max_questions]
    
    results = []
    
    # é€ä¸ªæµ‹è¯•
    for i, question in enumerate(questions, 1):
        print(f"[{i}/{len(questions)}] æµ‹è¯•é—®é¢˜ {question['id']}: {question['question'][:40]}...")
        
        result = test_single_question(question, workflow)
        results.append(result)
        
        # æ˜¾ç¤ºç»“æœ
        if result['error']:
            print(f"  âŒ é”™è¯¯: {result['error']}")
        else:
            status = "âœ…" if result['is_match'] else "âŒ"
            path = "FAQ" if result['is_faq'] else "å®Œæ•´"
            print(f"  {status} {result['match_type']} | {path}")
        
        # æ¯20ä¸ªæ˜¾ç¤ºè¿›åº¦
        if i % 20 == 0:
            matched = sum(1 for r in results if r['is_match'])
            print(f"  ğŸ“Š å½“å‰å‡†ç¡®ç‡: {matched/len(results)*100:.1f}%")
    
    return results


def generate_report(results):
    """ç”Ÿæˆç®€åŒ–æŠ¥å‘Š"""
    total = len(results)
    matched = sum(1 for r in results if r['is_match'])
    errors = sum(1 for r in results if r['error'])
    faq_count = sum(1 for r in results if r['is_faq'])
    
    # åŸºç¡€ç»Ÿè®¡
    stats = {
        'total': total,
        'matched': matched,
        'accuracy': f"{matched/total*100:.2f}%" if total > 0 else "0%",
        'errors': errors,
        'faq_usage': f"{faq_count/total*100:.1f}%" if total > 0 else "0%"
    }
    
    # åŒ¹é…ç±»å‹ç»Ÿè®¡
    match_types = {}
    for r in results:
        if r['is_match']:
            match_types[r['match_type']] = match_types.get(r['match_type'], 0) + 1
    
    print("\n" + "="*50)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»")
    print("="*50)
    print(f"æ€»é—®é¢˜æ•°: {stats['total']}")
    print(f"åŒ¹é…æ•°: {stats['matched']}")
    print(f"æ€»ä½“å‡†ç¡®ç‡: {stats['accuracy']}")
    print(f"é”™è¯¯æ•°: {stats['errors']}")
    print(f"FAQè·¯å¾„ä½¿ç”¨ç‡: {stats['faq_usage']}")
    print(f"åŒ¹é…ç±»å‹åˆ†å¸ƒ: {match_types}")
    
    return stats


def save_results(results, filename="test_results_252.json"):
    """ä¿å­˜æµ‹è¯•ç»“æœ"""
    # æ„å»ºä¿å­˜æ•°æ®
    report_data = {
        'test_info': {
            'test_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'total_questions': len(results),
            'description': '252é—®é¢˜è‡ªåŠ¨åŒ–æµ‹è¯•ç»“æœ'
        },
        'test_results': [
            {
                'question_id': r['id'],
                'original_question': r['question'],
                'table_name': r['table'],
                'expected_sql': r['expected_sql'],
                'generated_sql': r['actual_sql'],
                'is_match': r['is_match'],
                'match_type': r['match_type'],
                'is_faq_path': r['is_faq'],
                'error': r['error']
            }
            for r in results
        ]
    }
    
    # ä¿å­˜JSON
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(report_data, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ“„ æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {filename}")
    
    # ä¿å­˜ç®€åŒ–CSV
    csv_filename = filename.replace('.json', '.csv')
    try:
        with open(csv_filename, 'w', encoding='utf-8-sig') as f:
            f.write("é—®é¢˜ID,åŸå§‹é—®é¢˜,è¡¨å,æœŸæœ›SQL,ç”ŸæˆSQL,æ˜¯å¦åŒ¹é…,åŒ¹é…ç±»å‹,FAQè·¯å¾„,é”™è¯¯\n")
            for r in results:
                f.write(f'{r["id"]},"{r["question"]}","{r["table"]}","{r["expected_sql"]}","{r["actual_sql"]}",{r["is_match"]},{r["match_type"]},{r["is_faq"]},"{r["error"] or ""}"\n')
        print(f"ğŸ“Š CSVç»“æœå·²ä¿å­˜åˆ°: {csv_filename}")
    except:
        print("CSVä¿å­˜å¤±è´¥ï¼Œä½†JSONä¿å­˜æˆåŠŸ")


def execute_full_test(workflow, max_questions=None):
    """
    æ‰§è¡Œå®Œæ•´æµ‹è¯•æµç¨‹
    
    Args:
        workflow: å·¥ä½œæµå®ä¾‹
        max_questions: é™åˆ¶æµ‹è¯•é—®é¢˜æ•°ï¼ˆè°ƒè¯•ç”¨ï¼‰
    """
    try:
        print("ğŸ¯ å¼€å§‹252é—®é¢˜è‡ªåŠ¨åŒ–æµ‹è¯•ï¼ˆç®€åŒ–ç‰ˆï¼‰")
        
        # è¿è¡Œæµ‹è¯•
        results = run_all_tests(workflow, max_questions)
        
        # ç”ŸæˆæŠ¥å‘Š
        stats = generate_report(results)
        
        # ä¿å­˜ç»“æœ
        save_results(results)
        
        # æ˜¾ç¤ºä¸åŒ¹é…æ ·ä¾‹
        mismatched = [r for r in results if not r['is_match'] and not r['error']]
        if mismatched:
            print(f"\nğŸ” å‰5ä¸ªä¸åŒ¹é…æ ·ä¾‹:")
            for i, r in enumerate(mismatched[:5], 1):
                print(f"{i}. ID:{r['id']} - {r['question'][:50]}...")
                print(f"   åŒ¹é…ç±»å‹:{r['match_type']} | FAQè·¯å¾„:{r['is_faq']}")
        
        print(f"\nğŸ‰ æµ‹è¯•å®Œæˆï¼æ€»ä½“å‡†ç¡®ç‡: {stats['accuracy']}")
        return results
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


# ä½¿ç”¨è¯´æ˜
print("âœ… è¶…ç®€åŒ–ç‰ˆè‡ªåŠ¨åŒ–æµ‹è¯•ä»£ç å·²åŠ è½½ï¼")
print("ğŸ’¡ ä½¿ç”¨æ–¹æ³•:")
print("   execute_full_test(workflow)          # å®Œæ•´æµ‹è¯•252ä¸ªé—®é¢˜")
print("   execute_full_test(workflow, 10)      # è°ƒè¯•ï¼šä»…æµ‹è¯•å‰10ä¸ªé—®é¢˜")
print("ğŸ“Š ç»“æœè‡ªåŠ¨ä¿å­˜ä¸ºJSONå’ŒCSVä¸¤ç§æ ¼å¼")