{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26e7f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç¯å¢ƒè®¾ç½®\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# æ·»åŠ é¡¹ç›®è·¯å¾„\n",
    "project_root = Path.cwd()  # å‡è®¾å½“å‰åœ¨é¡¹ç›®æ ¹ç›®å½•\n",
    "if 'app' not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "# å¯¼å…¥å¿…è¦çš„åº“\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Optional\n",
    "import traceback\n",
    "import logging\n",
    "\n",
    "# å¯¼å…¥å·¥ä½œæµç›¸å…³æ¨¡å—\n",
    "from app.core.data.workflow_JINGFANG import DataQaWorkflow, WorkflowConfig\n",
    "from app.models import (\n",
    "    DataQACompletionRequest,\n",
    "    DataQAChatCompletionResponse,\n",
    "    ChatMessage as ModelChatMessage\n",
    ")\n",
    "from czce_ai.llm.chat import LLMChat as LLMModel\n",
    "from czce_ai.llm.message import Message as ChatMessage\n",
    "from czce_ai.utils.log import logger\n",
    "\n",
    "# è®¾ç½®æ—¥å¿—çº§åˆ«\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "print(\"ç¯å¢ƒè®¾ç½®å®Œæˆ\")\n",
    "print(f\"é¡¹ç›®æ ¹ç›®å½•: {project_root}\")\n",
    "print(f\"Pythonè·¯å¾„: {sys.path[:3]}\")  # åªæ˜¾ç¤ºå‰3ä¸ªè·¯å¾„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c2ee91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆå§‹åŒ–LLMæ¨¡å‹\n",
    "from app.core.components import qwen3_llm, qwen3_thinking_llm\n",
    "\n",
    "# æ³¨æ„ï¼šå¦‚æœé‡åˆ°å¯¼å…¥é”™è¯¯ï¼Œå¯èƒ½éœ€è¦ç›´æ¥åˆ›å»ºLLMå®ä¾‹\n",
    "try:\n",
    "    ans_llm = qwen3_llm\n",
    "    ans_thinking_llm = qwen3_thinking_llm\n",
    "    query_llm = qwen3_llm\n",
    "    print(\"ä½¿ç”¨é¢„å®šä¹‰çš„LLMå®ä¾‹\")\n",
    "except:\n",
    "    # å¤‡ç”¨æ–¹æ¡ˆï¼šç›´æ¥åˆ›å»ºLLMå®ä¾‹\n",
    "    from app.config.config import settings\n",
    "    ans_llm = LLMModel(model_name=\"qwen3\")\n",
    "    ans_thinking_llm = LLMModel(model_name=\"qwen3-thinking\")\n",
    "    query_llm = LLMModel(model_name=\"qwen3\")\n",
    "    print(\"åˆ›å»ºæ–°çš„LLMå®ä¾‹\")\n",
    "\n",
    "# é…ç½®å‚æ•°\n",
    "workflow_config = WorkflowConfig(\n",
    "    history_round=2,\n",
    "    follow_up_round=1,\n",
    "    reranking_threshold=0.2,\n",
    "    collection=\"hybrid_sql\",\n",
    "    domain_collection=\"domain_kl\",\n",
    "    max_table_results=3,\n",
    "    enable_entity_recognition=True,\n",
    "    enable_reranker=True\n",
    ")\n",
    "\n",
    "# åˆå§‹åŒ–å·¥ä½œæµ - ä½¿ç”¨æ‰©å±•å‚æ•°\n",
    "workflow = DataQaWorkflow(\n",
    "    ans_llm=ans_llm,\n",
    "    ans_thinking_llm=ans_thinking_llm,\n",
    "    query_llm=query_llm,\n",
    "    config=workflow_config,\n",
    "    history_round=2,\n",
    "    follow_up_round=1,\n",
    "    reranking_threshold=0.2,\n",
    "    knowledge_id=\"3cc33ed2-21fb-4452-9e10-528867bd5f99\",\n",
    "    bucket_name=\"czce-ai-dev\",\n",
    "    collection=\"hybrid_sql\",\n",
    "    use_cache=True\n",
    ")\n",
    "\n",
    "print(\"å·¥ä½œæµåˆå§‹åŒ–å®Œæˆ\")\n",
    "print(f\"FAQæ•°æ®å·²åŠ è½½: {len(workflow.faq_data)}æ¡\")\n",
    "print(f\"ç¼“å­˜æ–‡ä»¶ä½ç½®: {workflow.cache_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2417be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŸºäºæ‚¨çš„FAQçŸ¥è¯†åº“æ„é€ ä¸åŒç›¸ä¼¼åº¦çš„æµ‹è¯•æŸ¥è¯¢\n",
    "# æ³¨æ„ï¼šé«˜ç›¸ä¼¼åº¦é˜ˆå€¼æ˜¯0.9ï¼Œä¸æ˜¯0.85\n",
    "\n",
    "test_queries = {\n",
    "    # é«˜ç›¸ä¼¼åº¦æŸ¥è¯¢ (>=0.9) - å‡ ä¹å®Œå…¨åŒ¹é…FAQ\n",
    "    \"high_similarity\": [\n",
    "        \"æŸ¥è¯¢éƒ‘å•†æ‰€å½“å‰ä¸»åŠ›åˆçº¦çš„ä»£ç ã€ç»“ç®—ä»·åŠæˆäº¤é‡\",  # å®Œå…¨åŒ¹é…\n",
    "        \"ç­›é€‰å½“å‰ä¸»åŠ›åˆçº¦ç»“ç®—ä»·è¶…è¿‡2000å…ƒ/å¨çš„å“ç§\",    # å®Œå…¨åŒ¹é…\n",
    "        \"æ£‰èŠ±çœ‹æ¶¨æœŸæƒä¸»åŠ›åˆçº¦æŒä»“é‡å æ€»æŒä»“é‡çš„æ¯”ä¾‹æ˜¯å¤šå°‘\", # å®Œå…¨åŒ¹é…\n",
    "    ],\n",
    "    \n",
    "    # ä¸­ç­‰ç›¸ä¼¼åº¦æŸ¥è¯¢ (0.7-0.9) - ä¼šä½œä¸ºå‚è€ƒ\n",
    "    \"medium_similarity\": [\n",
    "        \"æŸ¥è¯¢éƒ‘å•†æ‰€ä¸»åŠ›åˆçº¦çš„ä»·æ ¼å’Œæˆäº¤æƒ…å†µ\",  # ç›¸ä¼¼ä½†ä¸å®Œå…¨ç›¸åŒ\n",
    "        \"ä¸»åŠ›åˆçº¦ç»“ç®—ä»·è¶…è¿‡2000çš„å“ç§\",       # ç®€åŒ–ç‰ˆæœ¬\n",
    "        \"æ£‰èŠ±æœŸæƒçš„æŒä»“å æ¯”\",                 # æ›´ç®€çŸ­çš„è¡¨è¿°\n",
    "    ],\n",
    "    \n",
    "    # ä½ç›¸ä¼¼åº¦æŸ¥è¯¢ (<0.7) - èµ°å®Œæ•´æµç¨‹\n",
    "    \"low_similarity\": [\n",
    "        \"ç»Ÿè®¡ä¸Šä¸ªæœˆçš„æœŸè´§äº¤æ˜“æ€»é¢\",\n",
    "        \"åˆ†ææœŸè´§å¸‚åœºçš„é£é™©æŒ‡æ ‡\",\n",
    "        \"è®¡ç®—æ‰€æœ‰äº¤æ˜“æ‰€çš„å¹³å‡æ‰‹ç»­è´¹\",\n",
    "    ],\n",
    "    \n",
    "    # éœ€è¦è¿½é—®çš„æŸ¥è¯¢\n",
    "    \"follow_up_needed\": [\n",
    "        \"æŸ¥è¯¢æˆäº¤é‡\",      # ç¼ºå°‘å“ç§å’Œæ—¶é—´\n",
    "        \"ç»Ÿè®¡æŒä»“é‡\",      # ç¼ºå°‘è¯¦ç»†ä¿¡æ¯\n",
    "        \"æœ€è¿‘çš„äº¤æ˜“æ•°æ®\",  # æ¨¡ç³ŠæŸ¥è¯¢\n",
    "    ],\n",
    "}\n",
    "\n",
    "print(\"æµ‹è¯•æ•°æ®æ„é€ å®Œæˆ\")\n",
    "for category, queries in test_queries.items():\n",
    "    print(f\"{category}: {len(queries)}ä¸ªæŸ¥è¯¢\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16662c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_entity_recognition():\n",
    "    \"\"\"æµ‹è¯•å¢å¼ºç‰ˆå®ä½“è¯†åˆ«åŠŸèƒ½ï¼ˆåŒ…å«åˆçº¦ä»£ç æ ‡å‡†åŒ–ï¼‰\"\"\"\n",
    "    print(\"=\" * 50)\n",
    "    print(\"ğŸ” æµ‹è¯• entity_recognition å‡½æ•°\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    test_queries = [\n",
    "        \"æŸ¥è¯¢FG2509çš„æˆäº¤é‡\",        # æ ‡å‡†åˆçº¦ä»£ç \n",
    "        \"æŸ¥è¯¢FG-2509çš„æˆäº¤é‡\",       # å¸¦åˆ†éš”ç¬¦çš„åˆçº¦ä»£ç \n",
    "        \"æŸ¥è¯¢fg_2509çš„æˆäº¤é‡\",       # å°å†™+ä¸‹åˆ’çº¿\n",
    "        \"æ£‰èŠ±CF2409åˆçº¦çš„ä»·æ ¼\",\n",
    "        \"è‹¹æœæœŸè´§AP2501çš„æŒä»“é‡\",\n",
    "        \"æŸ¥è¯¢ç™½ç³–SRçš„äº¤æ˜“æƒ…å†µ\",\n",
    "    ]\n",
    "    \n",
    "    for query in test_queries:\n",
    "        try:\n",
    "            enhanced = workflow.entity_recognition(query)\n",
    "            print(f\"åŸå§‹: {query}\")\n",
    "            print(f\"å¢å¼º: {enhanced}\")\n",
    "            \n",
    "            # æ£€æŸ¥åˆçº¦ä»£ç æ˜¯å¦è¢«æ­£ç¡®æ ‡å‡†åŒ–\n",
    "            if \"FG\" in query.upper():\n",
    "                assert \"FG2509(åˆçº¦)\" in enhanced or \"FG2509 (åˆçº¦)\" in enhanced, \"åˆçº¦ä»£ç æœªæ­£ç¡®æ ‡å‡†åŒ–\"\n",
    "            \n",
    "            print(\"é€šè¿‡\")\n",
    "            print(\"-\" * 30)\n",
    "        except Exception as e:\n",
    "            print(f\"é”™è¯¯å¤„ç† '{query}': {e}\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "# æ‰§è¡Œæµ‹è¯•\n",
    "test_entity_recognition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b37e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_semantic_search_faq():\n",
    "    \"\"\"æµ‹è¯•FAQè¯­ä¹‰æœç´¢åŠŸèƒ½\"\"\"\n",
    "    print(\"=\" * 50)\n",
    "    print(\"ğŸ” æµ‹è¯• semantic_search_faq å‡½æ•°\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # æ£€æŸ¥FAQæ•°æ®æ˜¯å¦å·²åŠ è½½\n",
    "    if not workflow.faq_data:\n",
    "        print(\"âš ï¸ FAQæ•°æ®æœªåŠ è½½ï¼Œå°è¯•é‡æ–°åŠ è½½...\")\n",
    "        workflow._load_faqs()\n",
    "    \n",
    "    print(f\"FAQæ•°æ®æ¡æ•°: {len(workflow.faq_data)}\")\n",
    "    \n",
    "    # æµ‹è¯•ä¸åŒç›¸ä¼¼åº¦çš„æŸ¥è¯¢\n",
    "    test_cases = [\n",
    "        (\"æŸ¥è¯¢éƒ‘å•†æ‰€å½“å‰ä¸»åŠ›åˆçº¦çš„ä»£ç ã€ç»“ç®—ä»·åŠæˆäº¤é‡\", \"é«˜ç›¸ä¼¼åº¦(>=0.9)\"),\n",
    "        (\"æŸ¥è¯¢ä¸»åŠ›åˆçº¦çš„ä»·æ ¼ä¿¡æ¯\", \"ä¸­ç­‰ç›¸ä¼¼åº¦(0.7-0.9)\"),\n",
    "        (\"è®¡ç®—å¹´åº¦æ€»æ”¶ç›Š\", \"ä½ç›¸ä¼¼åº¦(<0.7)\"),\n",
    "    ]\n",
    "    \n",
    "    for query, expected_similarity in test_cases:\n",
    "        try:\n",
    "            # å…ˆè¿›è¡Œå®ä½“è¯†åˆ«\n",
    "            enhanced_query = workflow.entity_recognition(query)\n",
    "            \n",
    "            # æ‰§è¡ŒFAQæœç´¢\n",
    "            results = workflow.semantic_search_faq(enhanced_query, top_k=3)\n",
    "            \n",
    "            print(f\"æŸ¥è¯¢: {query}\")\n",
    "            print(f\"å¢å¼º: {enhanced_query}\")\n",
    "            print(f\"æœŸæœ›: {expected_similarity}\")\n",
    "            \n",
    "            if results:\n",
    "                best_match = results[0]\n",
    "                print(f\"æœ€ä½³åŒ¹é…:\")\n",
    "                print(f\"  é—®é¢˜: {best_match['question'][:50]}...\")\n",
    "                print(f\"  ç›¸ä¼¼åº¦: {best_match['similarity']:.3f}\")\n",
    "                print(f\"  è¡¨: {best_match['table']}\")\n",
    "                \n",
    "                # éªŒè¯ç›¸ä¼¼åº¦èŒƒå›´\n",
    "                sim = best_match['similarity']\n",
    "                if sim >= 0.9:\n",
    "                    actual = \"é«˜ç›¸ä¼¼åº¦(>=0.9)\"\n",
    "                elif sim >= 0.7:\n",
    "                    actual = \"ä¸­ç­‰ç›¸ä¼¼åº¦(0.7-0.9)\"\n",
    "                else:\n",
    "                    actual = \"ä½ç›¸ä¼¼åº¦(<0.7)\"\n",
    "                print(f\"  å®é™…: {actual}\")\n",
    "            else:\n",
    "                print(\"  æœªæ‰¾åˆ°ç›¸å…³FAQ\")\n",
    "            \n",
    "            print(\"-\" * 30)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ é”™è¯¯: {e}\")\n",
    "            traceback.print_exc()\n",
    "    \n",
    "    return True\n",
    "\n",
    "# æ‰§è¡Œæµ‹è¯•\n",
    "test_semantic_search_faq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f216f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_e2e_high_similarity():\n",
    "    \"\"\"\n",
    "    ç«¯åˆ°ç«¯æµ‹è¯•ï¼šé«˜ç›¸ä¼¼åº¦FAQè·¯å¾„ (>=0.9)\n",
    "    æ³¨æ„ï¼šé˜ˆå€¼æ˜¯0.9ï¼Œä¸æ˜¯0.85\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"ğŸš€ ç«¯åˆ°ç«¯æµ‹è¯•ï¼šé«˜ç›¸ä¼¼åº¦FAQè·¯å¾„ (>=0.9)\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # ä½¿ç”¨ä¸FAQå®Œå…¨åŒ¹é…çš„æŸ¥è¯¢\n",
    "    user_query = \"æŸ¥è¯¢éƒ‘å•†æ‰€å½“å‰ä¸»åŠ›åˆçº¦çš„ä»£ç ã€ç»“ç®—ä»·åŠæˆäº¤é‡\"\n",
    "    print(f\"ğŸ“ ç”¨æˆ·æŸ¥è¯¢: {user_query}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    messages = [ChatMessage(role=\"user\", content=user_query)]\n",
    "    request = DataQACompletionRequest(\n",
    "        messages=messages,\n",
    "        model=\"test\",\n",
    "        created=int(datetime.now().timestamp()),\n",
    "        follow_up_num=0,\n",
    "        knowledge_base_ids=[\"3cc33ed2-21fb-4452-9e10-528867bd5f99\"],\n",
    "        use_reranker=True\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        print(\"âš™ï¸ æ‰§è¡Œdo_generateå‡½æ•°...\")\n",
    "        response = workflow.do_generate(\n",
    "            request=request,\n",
    "            enable_follow_up=False,\n",
    "            thinking=False\n",
    "        )\n",
    "        \n",
    "        # å±•ç¤ºæ‰§è¡Œè·¯å¾„\n",
    "        print(\"\\nğŸ“Š æ‰§è¡Œè·¯å¾„:\")\n",
    "        for step in response.steps:\n",
    "            print(f\"  Step {step.number}: {step.name} [{step.key}]\")\n",
    "            if step.key == \"semantic_search_faq\":\n",
    "                print(f\"    âœ {step.prompt}\")\n",
    "        \n",
    "        # æ£€æŸ¥æ˜¯å¦èµ°äº†FAQå¿«é€Ÿè·¯å¾„\n",
    "        print(\"\\nğŸ’ å“åº”åˆ†æ:\")\n",
    "        if response.model == \"faq\":\n",
    "            print(\"  âœ… æ¨¡å‹ç±»å‹: FAQ (å¿«é€Ÿè¿”å›)\")\n",
    "        else:\n",
    "            print(f\"  âš ï¸ æ¨¡å‹ç±»å‹: {response.model}\")\n",
    "        \n",
    "        if len(response.steps) == 3:\n",
    "            print(\"  âœ… æ­¥éª¤æ•°: 3 (FAQå¿«é€Ÿè·¯å¾„)\")\n",
    "        else:\n",
    "            print(f\"  âš ï¸ æ­¥éª¤æ•°: {len(response.steps)}\")\n",
    "        \n",
    "        # å±•ç¤ºSQLè¾“å‡º\n",
    "        if response.choices:\n",
    "            content = response.choices[0].message.content\n",
    "            if \"sql\" in content.lower():\n",
    "                print(\"\\nğŸ“„ SQLè¾“å‡º:\")\n",
    "                print(content[:500])\n",
    "        \n",
    "        return response\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ é”™è¯¯: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# æ‰§è¡Œæµ‹è¯•\n",
    "high_sim_response = test_e2e_high_similarity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafec19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_e2e_medium_similarity():\n",
    "    \"\"\"\n",
    "    ç«¯åˆ°ç«¯æµ‹è¯•ï¼šä¸­ç­‰ç›¸ä¼¼åº¦FAQè·¯å¾„ (0.7-0.9)\n",
    "    FAQä½œä¸ºå‚è€ƒï¼Œèµ°å®Œæ•´6æ­¥æµç¨‹\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"ç«¯åˆ°ç«¯æµ‹è¯•ï¼šä¸­ç­‰ç›¸ä¼¼åº¦FAQè·¯å¾„ (0.7-0.9)\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    user_query = \"æŸ¥è¯¢éƒ‘å•†æ‰€ä¸»åŠ›åˆçº¦çš„ä»·æ ¼ä¿¡æ¯\"\n",
    "    print(f\"ç”¨æˆ·æŸ¥è¯¢: {user_query}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    messages = [ChatMessage(role=\"user\", content=user_query)]\n",
    "    request = DataQACompletionRequest(\n",
    "        messages=messages,\n",
    "        model=\"test\",\n",
    "        created=int(datetime.now().timestamp()),\n",
    "        follow_up_num=0,\n",
    "        knowledge_base_ids=[\"3cc33ed2-21fb-4452-9e10-528867bd5f99\"],\n",
    "        use_reranker=True\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        print(\"æ‰§è¡Œdo_generateå‡½æ•°...\")\n",
    "        response = workflow.do_generate(\n",
    "            request=request,\n",
    "            enable_follow_up=False,\n",
    "            thinking=False\n",
    "        )\n",
    "        \n",
    "        # å±•ç¤ºå®Œæ•´æ‰§è¡Œè·¯å¾„\n",
    "        print(\"\\næ‰§è¡Œè·¯å¾„:\")\n",
    "        expected_steps = [\"modify_query\", \"entity_recognition\", \"semantic_search_faq\", \n",
    "                         \"locate_table\", \"generate_sql\"]\n",
    "        \n",
    "        for step in response.steps:\n",
    "            print(f\"  Step {step.number}: {step.name} [{step.key}]\")\n",
    "            if step.key in expected_steps:\n",
    "                expected_steps.remove(step.key)\n",
    "        \n",
    "        # éªŒè¯æ˜¯å¦èµ°äº†å®Œæ•´æµç¨‹\n",
    "        print(\"\\nè·¯å¾„éªŒè¯:\")\n",
    "        if len(response.steps) == 5:\n",
    "            print(\" æ­¥éª¤æ•°: 5 (å®Œæ•´æµç¨‹)\")\n",
    "            print(\" FAQä½œä¸ºå‚è€ƒæ·»åŠ åˆ°prompt\")\n",
    "        else:\n",
    "            print(f\" æ­¥éª¤æ•°: {len(response.steps)}\")\n",
    "        \n",
    "        if not expected_steps:\n",
    "            print(\"  æ‰€æœ‰é¢„æœŸæ­¥éª¤éƒ½å·²æ‰§è¡Œ\")\n",
    "        else:\n",
    "            print(f\" ç¼ºå°‘æ­¥éª¤: {expected_steps}\")\n",
    "        \n",
    "        return response\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"é”™è¯¯: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# æ‰§è¡Œæµ‹è¯•\n",
    "medium_sim_response = test_e2e_medium_similarity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c3d155",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_e2e_low_similarity():\n",
    "    \"\"\"\n",
    "    ç«¯åˆ°ç«¯æµ‹è¯•ï¼šä½ç›¸ä¼¼åº¦è·¯å¾„ (<0.7)\n",
    "    æ— FAQå‚è€ƒï¼Œèµ°å®Œæ•´6æ­¥æµç¨‹\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"ğŸ”§ ç«¯åˆ°ç«¯æµ‹è¯•ï¼šä½ç›¸ä¼¼åº¦è·¯å¾„ (<0.7)\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    user_query = \"ç»Ÿè®¡ä¸Šä¸ªæœˆæ‰€æœ‰äº¤æ˜“æ‰€çš„æœŸè´§æ€»äº¤æ˜“é¢\"\n",
    "    print(f\"ğŸ“ ç”¨æˆ·æŸ¥è¯¢: {user_query}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    messages = [ChatMessage(role=\"user\", content=user_query)]\n",
    "    request = DataQACompletionRequest(\n",
    "        messages=messages,\n",
    "        model=\"test\",\n",
    "        created=int(datetime.now().timestamp()),\n",
    "        follow_up_num=0,\n",
    "        knowledge_base_ids=[\"3cc33ed2-21fb-4452-9e10-528867bd5f99\"],\n",
    "        use_reranker=True\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        print(\"âš™ï¸ æ‰§è¡Œdo_generateå‡½æ•°...\")\n",
    "        response = workflow.do_generate(\n",
    "            request=request,\n",
    "            enable_follow_up=False,\n",
    "            thinking=False\n",
    "        )\n",
    "        \n",
    "        # å±•ç¤ºæ‰§è¡Œè·¯å¾„\n",
    "        print(\"\\nğŸ“Š æ‰§è¡Œè·¯å¾„:\")\n",
    "        has_faq_reference = False\n",
    "        \n",
    "        for step in response.steps:\n",
    "            print(f\"  Step {step.number}: {step.name} [{step.key}]\")\n",
    "            if step.key == \"semantic_search_faq\":\n",
    "                if \"æ²¡æœ‰æ‰¾åˆ°\" in str(step.prompt) or \"ä¸æ»¡è¶³\" in str(step.prompt):\n",
    "                    print(f\"    âœ FAQç›¸ä¼¼åº¦è¿‡ä½ï¼Œä¸ä½œä¸ºå‚è€ƒ\")\n",
    "            elif step.key == \"generate_single_table_prompt\":\n",
    "                # æ£€æŸ¥promptä¸­æ˜¯å¦æœ‰FAQå‚è€ƒ\n",
    "                if \"å‚è€ƒç¤ºä¾‹\" in str(step.prompt):\n",
    "                    has_faq_reference = True\n",
    "        \n",
    "        # éªŒè¯è·¯å¾„\n",
    "        print(\"\\nğŸ’ è·¯å¾„éªŒè¯:\")\n",
    "        if len(response.steps) == 6 and not has_faq_reference:\n",
    "            print(\"  âœ… æ­¥éª¤æ•°: 6 (å®Œæ•´æµç¨‹)\")\n",
    "            print(\"  âœ… æ— FAQå‚è€ƒï¼ˆç›¸ä¼¼åº¦<0.7ï¼‰\")\n",
    "            print(\"  âœ… çº¯LLMç”ŸæˆSQL\")\n",
    "        else:\n",
    "            print(f\"  âš ï¸ æ­¥éª¤æ•°: {len(response.steps)}\")\n",
    "            if has_faq_reference:\n",
    "                print(\"  âš ï¸ æ„å¤–åŒ…å«FAQå‚è€ƒ\")\n",
    "        \n",
    "        return response\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ é”™è¯¯: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# æ‰§è¡Œæµ‹è¯•\n",
    "low_sim_response = test_e2e_low_similarity()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
