{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4bd8288",
   "metadata": {},
   "source": [
    "Cell 1: ç¯å¢ƒè®¾ç½®å’Œå¯¼å…¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca6e51a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ç¯å¢ƒè®¾ç½®\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# æ·»åŠ é¡¹ç›®è·¯å¾„\n",
    "project_root = Path.cwd().parent  # æ ¹æ®æ‚¨çš„é¡¹ç›®ç»“æ„è°ƒæ•´\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# å¯¼å…¥å¿…è¦çš„åº“\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Optional\n",
    "import traceback\n",
    "\n",
    "# å¯¼å…¥å·¥ä½œæµç›¸å…³æ¨¡å—\n",
    "from data_qa.workflow_enhanced import DataQaWorkflow, WorkflowConfig\n",
    "from app.models import (\n",
    "    DataQACompletionRequest,\n",
    "    DataQAChatCompletionResponse,\n",
    "    ChatMessage\n",
    ")\n",
    "from czce_ai.llm.chat import LLMChat as LLMModel\n",
    "from czce_ai.utils.log import logger\n",
    "\n",
    "# è®¾ç½®æ—¥å¿—çº§åˆ«\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "print(\"âœ… ç¯å¢ƒè®¾ç½®å®Œæˆ\")\n",
    "print(f\"é¡¹ç›®æ ¹ç›®å½•: {project_root}\")\n",
    "print(f\"Pythonè·¯å¾„: {sys.path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fdc624",
   "metadata": {},
   "source": [
    "Cell 2: åˆå§‹åŒ–LLMå®¢æˆ·ç«¯å’Œå·¥ä½œæµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f97bcb9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# åˆå§‹åŒ–LLMæ¨¡å‹ï¼ˆæ ¹æ®æ‚¨çš„å®é™…é…ç½®è°ƒæ•´ï¼‰\n",
    "from app.core.components import qwen3_llm, qwen3_thinking_llm\n",
    "\n",
    "# åˆ›å»ºLLMå®ä¾‹\n",
    "ans_llm = qwen3_llm  # ç­”æ¡ˆç”ŸæˆLLM\n",
    "ans_thinking_llm = qwen3_thinking_llm  # æ€è€ƒæ¨¡å¼LLM\n",
    "query_llm = qwen3_llm  # æŸ¥è¯¢ä¼˜åŒ–LLM\n",
    "\n",
    "# é…ç½®å‚æ•°\n",
    "workflow_config = WorkflowConfig(\n",
    "    history_round=2,  # å†å²å¯¹è¯è½®æ•°\n",
    "    follow_up_round=1,  # è¿½é—®è½®æ•°\n",
    "    reranking_threshold=0.2,\n",
    "    collection=\"hybrid_sql\",\n",
    "    enable_entity_recognition=True,\n",
    "    enable_reranker=True\n",
    ")\n",
    "\n",
    "# åˆå§‹åŒ–å·¥ä½œæµ\n",
    "workflow = DataQaWorkflow(\n",
    "    ans_llm=ans_llm,\n",
    "    ans_thinking_llm=ans_thinking_llm,\n",
    "    query_llm=query_llm,\n",
    "    history_round=2,\n",
    "    reranking_threshold=0.2,\n",
    "    config=workflow_config,\n",
    "    knowledge_id=\"3cc33ed2-21fb-4452-9e10-528867bd5f99\",  # æ‚¨çš„çŸ¥è¯†åº“ID\n",
    "    bucket_name=\"czce-ai-dev\",\n",
    "    collection=\"hybrid_sql\",\n",
    "    use_cache=True  # ä½¿ç”¨FAQç¼“å­˜\n",
    ")\n",
    "\n",
    "print(\"âœ… å·¥ä½œæµåˆå§‹åŒ–å®Œæˆ\")\n",
    "print(f\"FAQæ•°æ®å·²åŠ è½½: {len(workflow.faq_data)}æ¡\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a403ba",
   "metadata": {},
   "source": [
    "Cell 3: æ„é€ æµ‹è¯•æ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786b05c1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# åŸºäºFAQçŸ¥è¯†åº“æ„é€ ä¸åŒç›¸ä¼¼åº¦çš„æµ‹è¯•æŸ¥è¯¢\n",
    "\n",
    "# æµ‹è¯•æ•°æ®é›†\n",
    "test_queries = {\n",
    "    # é«˜ç›¸ä¼¼åº¦æŸ¥è¯¢ (>=0.85) - è¿™äº›åº”è¯¥ç›´æ¥ä»FAQè¿”å›ç»“æœ\n",
    "    \"high_similarity\": [\n",
    "        \"æŸ¥è¯¢éƒ‘å•†æ‰€å½“å‰ä¸»åŠ›åˆçº¦çš„ä»£ç ã€ç»“ç®—ä»·åŠæˆäº¤é‡\",  # å®Œå…¨åŒ¹é…FAQ\n",
    "        \"ç­›é€‰å½“å‰ä¸»åŠ›åˆçº¦ç»“ç®—ä»·è¶…è¿‡2000å…ƒ/å¨çš„å“ç§\",  # å®Œå…¨åŒ¹é…FAQ\n",
    "        \"æŸ¥è¯¢éƒ‘å•†æ‰€å½“å‰æŠ•æœºæˆäº¤é‡å æ€»æˆäº¤é‡å æ¯”è¶…è¿‡50%çš„å“ç§\",  # å‡ ä¹å®Œå…¨åŒ¹é…\n",
    "    ],\n",
    "    \n",
    "    # ä¸­ç­‰ç›¸ä¼¼åº¦æŸ¥è¯¢ (0.7-0.85) - è¿™äº›ä¼šä½œä¸ºå‚è€ƒæ·»åŠ åˆ°prompt\n",
    "    \"medium_similarity\": [\n",
    "        \"æŸ¥è¯¢éƒ‘å•†æ‰€ä¸»åŠ›åˆçº¦çš„ä»·æ ¼å’Œæˆäº¤æƒ…å†µ\",  # ä¸FAQç±»ä¼¼ä½†ä¸å®Œå…¨ç›¸åŒ\n",
    "        \"éƒ‘å•†æ‰€å½“å‰çš„ä¸»è¦åˆçº¦ä¿¡æ¯\",  # ç®€åŒ–ç‰ˆæœ¬\n",
    "        \"ä¸»åŠ›åˆçº¦ç»“ç®—ä»·å¤§äº2000çš„å“ç§æœ‰å“ªäº›\",  # è¡¨è¿°ç•¥æœ‰ä¸åŒ\n",
    "    ],\n",
    "    \n",
    "    # ä½ç›¸ä¼¼åº¦æŸ¥è¯¢ (<0.7) - è¿™äº›ä¼šèµ°å®Œæ•´çš„è¡¨æ ¼å®šä½å’ŒSQLç”Ÿæˆæµç¨‹\n",
    "    \"low_similarity\": [\n",
    "        \"ç»Ÿè®¡ä¸Šä¸ªæœˆçš„æœŸè´§äº¤æ˜“æ€»é¢\",  # ä¸FAQå·®å¼‚è¾ƒå¤§\n",
    "        \"åˆ†ææœŸè´§å¸‚åœºçš„é£é™©æŒ‡æ ‡\",  # å®Œå…¨ä¸åŒçš„æŸ¥è¯¢\n",
    "        \"è®¡ç®—æ‰€æœ‰äº¤æ˜“æ‰€çš„å¹³å‡æ‰‹ç»­è´¹\",  # æ–°çš„æŸ¥è¯¢ç±»å‹\n",
    "    ],\n",
    "    \n",
    "    # éœ€è¦è¿½é—®çš„æŸ¥è¯¢ï¼ˆä¿¡æ¯ä¸è¶³ï¼‰\n",
    "    \"follow_up_needed\": [\n",
    "        \"æŸ¥è¯¢æˆäº¤é‡\",  # ç¼ºå°‘å…·ä½“å“ç§å’Œæ—¶é—´\n",
    "        \"ç»Ÿè®¡æŒä»“é‡\",  # ç¼ºå°‘è¯¦ç»†ä¿¡æ¯\n",
    "        \"æœ€è¿‘çš„äº¤æ˜“æ•°æ®\",  # æ¨¡ç³ŠæŸ¥è¯¢\n",
    "    ],\n",
    "}\n",
    "\n",
    "print(\"âœ… æµ‹è¯•æ•°æ®æ„é€ å®Œæˆ\")\n",
    "print(f\"é«˜ç›¸ä¼¼åº¦æŸ¥è¯¢: {len(test_queries['high_similarity'])}ä¸ª\")\n",
    "print(f\"ä¸­ç­‰ç›¸ä¼¼åº¦æŸ¥è¯¢: {len(test_queries['medium_similarity'])}ä¸ª\")\n",
    "print(f\"ä½ç›¸ä¼¼åº¦æŸ¥è¯¢: {len(test_queries['low_similarity'])}ä¸ª\")\n",
    "print(f\"éœ€è¦è¿½é—®çš„æŸ¥è¯¢: {len(test_queries['follow_up_needed'])}ä¸ª\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74dc7e3",
   "metadata": {},
   "source": [
    "Cell 4: æµ‹è¯•å•ä¸ªå‡½æ•° - modify_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939051b5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def test_modify_query():\n",
    "    \"\"\"æµ‹è¯•é—®é¢˜æ”¹å†™åŠŸèƒ½\"\"\"\n",
    "    print(\"=\" * 50)\n",
    "    print(\"ğŸ“ æµ‹è¯• modify_query å‡½æ•°\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    test_messages = [\n",
    "        ChatMessage(role=\"user\", content=\"æŸ¥è¯¢æ£‰èŠ±çš„æˆäº¤é‡å’Œä»·æ ¼\")\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        # åˆ›å»ºè¯·æ±‚å¯¹è±¡\n",
    "        request = DataQACompletionRequest(\n",
    "            messages=test_messages,\n",
    "            model=\"test\",\n",
    "            created=int(datetime.now().timestamp())\n",
    "        )\n",
    "        \n",
    "        # æå–æ¶ˆæ¯\n",
    "        input_messages = workflow._extract_input_messages(request)\n",
    "        \n",
    "        # æ‰§è¡Œé—®é¢˜æ”¹å†™\n",
    "        optimized_query = workflow.modify_query(\n",
    "            input_messages=input_messages,\n",
    "            enable_follow_up=True\n",
    "        )\n",
    "        \n",
    "        print(f\"âœ… åŸå§‹æŸ¥è¯¢: {test_messages[0].content}\")\n",
    "        print(f\"âœ… æ”¹å†™åæŸ¥è¯¢: {optimized_query.rewritten_query}\")\n",
    "        print(f\"âœ… æ˜¯å¦å……åˆ†: {optimized_query.is_sufficient}\")\n",
    "        \n",
    "        return optimized_query\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ é”™è¯¯: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# æ‰§è¡Œæµ‹è¯•\n",
    "result = test_modify_query()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90dff82",
   "metadata": {},
   "source": [
    "Cell 5: æµ‹è¯•å•ä¸ªå‡½æ•° - entity_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8ff527",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def test_entity_recognition():\n",
    "    \"\"\"æµ‹è¯•å®ä½“è¯†åˆ«åŠŸèƒ½\"\"\"\n",
    "    print(\"=\" * 50)\n",
    "    print(\"ğŸ” æµ‹è¯• entity_recognition å‡½æ•°\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    test_queries = [\n",
    "        \"æŸ¥è¯¢FG2509çš„æˆäº¤é‡\",\n",
    "        \"æ£‰èŠ±CF2409åˆçº¦çš„ä»·æ ¼\",\n",
    "        \"è‹¹æœæœŸè´§AP2501çš„æŒä»“é‡\",\n",
    "        \"æŸ¥è¯¢ç™½ç³–SRçš„äº¤æ˜“æƒ…å†µ\"\n",
    "    ]\n",
    "    \n",
    "    for query in test_queries:\n",
    "        try:\n",
    "            enhanced = workflow.entity_recognition(query)\n",
    "            print(f\"åŸå§‹: {query}\")\n",
    "            print(f\"å¢å¼º: {enhanced}\")\n",
    "            print(\"-\" * 30)\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ é”™è¯¯å¤„ç† '{query}': {e}\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "# æ‰§è¡Œæµ‹è¯•\n",
    "test_entity_recognition()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6692106b",
   "metadata": {},
   "source": [
    "Cell 6: æµ‹è¯•å•ä¸ªå‡½æ•° - semantic_search_faq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1d67da",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def test_semantic_search_faq():\n",
    "    \"\"\"æµ‹è¯•FAQè¯­ä¹‰æœç´¢åŠŸèƒ½\"\"\"\n",
    "    print(\"=\" * 50)\n",
    "    print(\"ğŸ” æµ‹è¯• semantic_search_faq å‡½æ•°\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # æµ‹è¯•ä¸åŒç›¸ä¼¼åº¦çš„æŸ¥è¯¢\n",
    "    test_cases = [\n",
    "        (\"æŸ¥è¯¢éƒ‘å•†æ‰€å½“å‰ä¸»åŠ›åˆçº¦çš„ä»£ç ã€ç»“ç®—ä»·åŠæˆäº¤é‡\", \"é«˜ç›¸ä¼¼åº¦\"),\n",
    "        (\"æŸ¥è¯¢ä¸»åŠ›åˆçº¦çš„ä»·æ ¼ä¿¡æ¯\", \"ä¸­ç­‰ç›¸ä¼¼åº¦\"),\n",
    "        (\"è®¡ç®—å¹´åº¦æ€»æ”¶ç›Š\", \"ä½ç›¸ä¼¼åº¦\"),\n",
    "    ]\n",
    "    \n",
    "    for query, expected_similarity in test_cases:\n",
    "        try:\n",
    "            # å…ˆè¿›è¡Œå®ä½“è¯†åˆ«\n",
    "            enhanced_query = workflow.entity_recognition(query)\n",
    "            \n",
    "            # æ‰§è¡ŒFAQæœç´¢\n",
    "            results = workflow.semantic_search_faq(enhanced_query, top_k=3)\n",
    "            \n",
    "            print(f\"æŸ¥è¯¢: {query}\")\n",
    "            print(f\"å¢å¼ºæŸ¥è¯¢: {enhanced_query}\")\n",
    "            print(f\"æœŸæœ›ç›¸ä¼¼åº¦: {expected_similarity}\")\n",
    "            \n",
    "            if results:\n",
    "                for i, result in enumerate(results[:2], 1):  # åªæ˜¾ç¤ºå‰2ä¸ªç»“æœ\n",
    "                    print(f\"  ç»“æœ{i}:\")\n",
    "                    print(f\"    é—®é¢˜: {result['question'][:50]}...\")\n",
    "                    print(f\"    ç›¸ä¼¼åº¦: {result['similarity']:.3f}\")\n",
    "                    print(f\"    è¡¨: {result['table']}\")\n",
    "            else:\n",
    "                print(\"  æœªæ‰¾åˆ°ç›¸å…³FAQ\")\n",
    "            \n",
    "            print(\"-\" * 30)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ é”™è¯¯: {e}\")\n",
    "            traceback.print_exc()\n",
    "    \n",
    "    return True\n",
    "\n",
    "# æ‰§è¡Œæµ‹è¯•\n",
    "test_semantic_search_faq()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4350d47",
   "metadata": {},
   "source": [
    "Cell 7: ç«¯åˆ°ç«¯æµ‹è¯• - é«˜ç›¸ä¼¼åº¦è·¯å¾„ (>=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3783aed6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def test_e2e_high_similarity():\n",
    "    \"\"\"\n",
    "    ç«¯åˆ°ç«¯æµ‹è¯•ï¼šé«˜ç›¸ä¼¼åº¦FAQè·¯å¾„\n",
    "    User Query -> Step1-3 -> SQL Output (FAQç›´æ¥è¿”å›)\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"ğŸš€ ç«¯åˆ°ç«¯æµ‹è¯•ï¼šé«˜ç›¸ä¼¼åº¦FAQè·¯å¾„ (>=0.85)\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # ä½¿ç”¨ä¸FAQå®Œå…¨åŒ¹é…çš„æŸ¥è¯¢\n",
    "    user_query = \"æŸ¥è¯¢éƒ‘å•†æ‰€å½“å‰ä¸»åŠ›åˆçº¦çš„ä»£ç ã€ç»“ç®—ä»·åŠæˆäº¤é‡\"\n",
    "    print(f\"ğŸ“ ç”¨æˆ·æŸ¥è¯¢: {user_query}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    messages = [ChatMessage(role=\"user\", content=user_query)]\n",
    "    request = DataQACompletionRequest(\n",
    "        messages=messages,\n",
    "        model=\"test\",\n",
    "        created=int(datetime.now().timestamp()),\n",
    "        follow_up_num=0\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # æ‰§è¡Œå®Œæ•´æµç¨‹\n",
    "        print(\"âš™ï¸ æ‰§è¡Œdo_generateå‡½æ•°...\")\n",
    "        response = workflow.do_generate(\n",
    "            request=request,\n",
    "            enable_follow_up=False,\n",
    "            thinking=False\n",
    "        )\n",
    "        \n",
    "        # å±•ç¤ºæ‰§è¡Œè·¯å¾„\n",
    "        print(\"\\nğŸ“Š æ‰§è¡Œè·¯å¾„:\")\n",
    "        for i, step in enumerate(response.steps, 1):\n",
    "            print(f\"  Step {step.number}: {step.name} [{step.key}]\")\n",
    "            if step.key == \"modify_query\":\n",
    "                print(f\"    âœ æ”¹å†™å: {step.prompt}\")\n",
    "            elif step.key == \"query_entity_recognition\":\n",
    "                print(f\"    âœ å®ä½“è¯†åˆ«å: {step.prompt}\")\n",
    "            elif step.key == \"semantic_search_faq\":\n",
    "                print(f\"    âœ FAQåŒ¹é…: {step.prompt}\")\n",
    "        \n",
    "        # å±•ç¤ºæœ€ç»ˆSQLè¾“å‡º\n",
    "        print(\"\\nğŸ’ æœ€ç»ˆè¾“å‡º:\")\n",
    "        if response.choices:\n",
    "            content = response.choices[0].message.content\n",
    "            # æå–SQLéƒ¨åˆ†\n",
    "            if \"```sql\" in content:\n",
    "                sql_start = content.find(\"```sql\") + 6\n",
    "                sql_end = content.find(\"```\", sql_start)\n",
    "                sql = content[sql_start:sql_end].strip()\n",
    "                print(\"  SQLæŸ¥è¯¢:\")\n",
    "                print(\"  \" + \"-\" * 76)\n",
    "                for line in sql.split('\\n'):\n",
    "                    print(f\"  {line}\")\n",
    "                print(\"  \" + \"-\" * 76)\n",
    "            else:\n",
    "                print(f\"  å“åº”å†…å®¹: {content[:200]}...\")\n",
    "        \n",
    "        # éªŒè¯è·¯å¾„\n",
    "        print(\"\\nâœ… éªŒè¯ç»“æœ:\")\n",
    "        if len(response.steps) == 3 and response.model == \"faq\":\n",
    "            print(\"  âœ“ é«˜ç›¸ä¼¼åº¦FAQå¿«é€Ÿè·¯å¾„éªŒè¯æˆåŠŸï¼\")\n",
    "            print(\"  âœ“ æ‰§è¡Œæ­¥éª¤æ•°: 3 (Step1â†’Step2â†’Step3)\")\n",
    "            print(\"  âœ“ ç›´æ¥ä»FAQè¿”å›SQLï¼Œæœªè°ƒç”¨LLM\")\n",
    "        else:\n",
    "            print(f\"  âš ï¸ æœªèµ°é¢„æœŸè·¯å¾„ï¼Œå®é™…æ­¥éª¤æ•°: {len(response.steps)}\")\n",
    "        \n",
    "        return response\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ é”™è¯¯: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# æ‰§è¡Œæµ‹è¯•\n",
    "high_sim_response = test_e2e_high_similarity()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144d5983",
   "metadata": {},
   "source": [
    "Cell 8: ç«¯åˆ°ç«¯æµ‹è¯• - ä¸­ç­‰ç›¸ä¼¼åº¦è·¯å¾„ (0.7-0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cc7b35",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def test_e2e_medium_similarity():\n",
    "    \"\"\"\n",
    "    ç«¯åˆ°ç«¯æµ‹è¯•ï¼šä¸­ç­‰ç›¸ä¼¼åº¦FAQè·¯å¾„\n",
    "    User Query -> Step1-6 -> SQL Output (FAQä½œä¸ºå‚è€ƒ)\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"ğŸ“š ç«¯åˆ°ç«¯æµ‹è¯•ï¼šä¸­ç­‰ç›¸ä¼¼åº¦FAQè·¯å¾„ (0.7-0.85)\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # ä½¿ç”¨ä¸FAQç›¸ä¼¼ä½†ä¸å®Œå…¨åŒ¹é…çš„æŸ¥è¯¢\n",
    "    user_query = \"æŸ¥è¯¢éƒ‘å•†æ‰€ä¸»åŠ›åˆçº¦çš„ä»·æ ¼å’Œäº¤æ˜“æƒ…å†µ\"\n",
    "    print(f\"ğŸ“ ç”¨æˆ·æŸ¥è¯¢: {user_query}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    messages = [ChatMessage(role=\"user\", content=user_query)]\n",
    "    request = DataQACompletionRequest(\n",
    "        messages=messages,\n",
    "        model=\"test\",\n",
    "        created=int(datetime.now().timestamp()),\n",
    "        follow_up_num=0\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        print(\"âš™ï¸ æ‰§è¡Œdo_generateå‡½æ•°...\")\n",
    "        response = workflow.do_generate(\n",
    "            request=request,\n",
    "            enable_follow_up=False,\n",
    "            thinking=False\n",
    "        )\n",
    "        \n",
    "        # å±•ç¤ºå®Œæ•´æ‰§è¡Œè·¯å¾„\n",
    "        print(\"\\nğŸ“Š æ‰§è¡Œè·¯å¾„:\")\n",
    "        for i, step in enumerate(response.steps, 1):\n",
    "            print(f\"  Step {step.number}: {step.name} [{step.key}]\")\n",
    "            \n",
    "            # å±•ç¤ºæ¯ä¸ªæ­¥éª¤çš„è¯¦ç»†ä¿¡æ¯\n",
    "            if step.key == \"modify_query\":\n",
    "                print(f\"    âœ æ”¹å†™: {step.prompt[:50]}...\")\n",
    "            elif step.key == \"query_entity_recognition\":\n",
    "                print(f\"    âœ å®ä½“è¯†åˆ«: {step.prompt[:50]}...\")\n",
    "            elif step.key == \"semantic_search_faq\":\n",
    "                print(f\"    âœ FAQæœç´¢: {step.prompt}\")\n",
    "            elif step.key == \"locate_table\":\n",
    "                # è§£æè¡¨æ ¼å®šä½ç»“æœ\n",
    "                if isinstance(step.prompt, list) and len(step.prompt) > 0:\n",
    "                    print(f\"    âœ å®šä½åˆ° {len(step.prompt)} ä¸ªè¡¨\")\n",
    "                    for idx, table in enumerate(step.prompt[:2], 1):  # åªæ˜¾ç¤ºå‰2ä¸ª\n",
    "                        if isinstance(table, dict):\n",
    "                            print(f\"       è¡¨{idx}: {table.get('table_name', 'N/A')} (åˆ†æ•°: {table.get('score', 0):.3f})\")\n",
    "            elif step.key == \"generate_prompt\":\n",
    "                print(f\"    âœ ç”Ÿæˆæç¤ºè¯é•¿åº¦: {len(str(step.prompt))} å­—ç¬¦\")\n",
    "                if \"å‚è€ƒç¤ºä¾‹\" in str(step.prompt):\n",
    "                    print(f\"       âœ“ åŒ…å«FAQå‚è€ƒ\")\n",
    "            elif step.key == \"generate_sql\":\n",
    "                print(f\"    âœ SQLç”Ÿæˆå®Œæˆ\")\n",
    "        \n",
    "        # å±•ç¤ºæœ€ç»ˆSQLè¾“å‡º\n",
    "        print(\"\\nğŸ’ æœ€ç»ˆSQLè¾“å‡º:\")\n",
    "        if response.choices:\n",
    "            content = response.choices[0].message.content\n",
    "            if \"```sql\" in content or \"SELECT\" in content.upper():\n",
    "                # å°è¯•æå–SQL\n",
    "                if \"```sql\" in content:\n",
    "                    sql_start = content.find(\"```sql\") + 6\n",
    "                    sql_end = content.find(\"```\", sql_start)\n",
    "                    sql = content[sql_start:sql_end].strip()\n",
    "                else:\n",
    "                    # æŸ¥æ‰¾SELECTè¯­å¥\n",
    "                    import re\n",
    "                    sql_pattern = r'(SELECT[\\s\\S]+?(?:;|$))'\n",
    "                    match = re.search(sql_pattern, content, re.IGNORECASE)\n",
    "                    sql = match.group(1) if match else content[:200]\n",
    "                \n",
    "                print(\"  \" + \"-\" * 76)\n",
    "                for line in sql.split('\\n')[:10]:  # æœ€å¤šæ˜¾ç¤º10è¡Œ\n",
    "                    print(f\"  {line}\")\n",
    "                print(\"  \" + \"-\" * 76)\n",
    "        \n",
    "        # éªŒè¯è·¯å¾„\n",
    "        print(\"\\nâœ… éªŒè¯ç»“æœ:\")\n",
    "        expected_steps = [\"modify_query\", \"query_entity_recognition\", \"semantic_search_faq\", \n",
    "                         \"locate_table\", \"generate_prompt\", \"generate_sql\"]\n",
    "        actual_steps = [step.key for step in response.steps]\n",
    "        \n",
    "        if len(response.steps) == 6:\n",
    "            print(\"  âœ“ ä¸­ç­‰ç›¸ä¼¼åº¦å®Œæ•´è·¯å¾„éªŒè¯æˆåŠŸï¼\")\n",
    "            print(\"  âœ“ æ‰§è¡Œæ­¥éª¤æ•°: 6 (å®Œæ•´æµç¨‹)\")\n",
    "            print(\"  âœ“ FAQä½œä¸ºå‚è€ƒå¢å¼ºäº†prompt\")\n",
    "            print(\"  âœ“ æœ€ç»ˆé€šè¿‡LLMç”ŸæˆSQL\")\n",
    "        else:\n",
    "            print(f\"  âš ï¸ æ­¥éª¤æ•°ä¸åŒ¹é…ï¼Œé¢„æœŸ6ä¸ªï¼Œå®é™…{len(response.steps)}ä¸ª\")\n",
    "            \n",
    "        return response\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ é”™è¯¯: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# æ‰§è¡Œæµ‹è¯•\n",
    "medium_sim_response = test_e2e_medium_similarity()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e950a7",
   "metadata": {},
   "source": [
    "Cell 9: ç«¯åˆ°ç«¯æµ‹è¯• - ä½ç›¸ä¼¼åº¦è·¯å¾„ (<0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bada2842",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def test_e2e_low_similarity():\n",
    "    \"\"\"\n",
    "    ç«¯åˆ°ç«¯æµ‹è¯•ï¼šä½ç›¸ä¼¼åº¦è·¯å¾„\n",
    "    User Query -> Step1-6 -> SQL Output (æ— FAQå‚è€ƒ)\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"ğŸ”§ ç«¯åˆ°ç«¯æµ‹è¯•ï¼šä½ç›¸ä¼¼åº¦è·¯å¾„ (<0.7)\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # ä½¿ç”¨ä¸FAQå·®å¼‚è¾ƒå¤§çš„æŸ¥è¯¢\n",
    "    user_query = \"ç»Ÿè®¡ä¸Šä¸ªæœˆæ‰€æœ‰äº¤æ˜“æ‰€çš„æœŸè´§æ€»äº¤æ˜“é¢å’Œå¹³å‡æ‰‹ç»­è´¹\"\n",
    "    print(f\"ğŸ“ ç”¨æˆ·æŸ¥è¯¢: {user_query}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    messages = [ChatMessage(role=\"user\", content=user_query)]\n",
    "    request = DataQACompletionRequest(\n",
    "        messages=messages,\n",
    "        model=\"test\",\n",
    "        created=int(datetime.now().timestamp()),\n",
    "        follow_up_num=0\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        print(\"âš™ï¸ æ‰§è¡Œdo_generateå‡½æ•°...\")\n",
    "        response = workflow.do_generate(\n",
    "            request=request,\n",
    "            enable_follow_up=False,\n",
    "            thinking=False\n",
    "        )\n",
    "        \n",
    "        # å±•ç¤ºå®Œæ•´æ‰§è¡Œè·¯å¾„\n",
    "        print(\"\\nğŸ“Š æ‰§è¡Œè·¯å¾„:\")\n",
    "        has_faq_reference = False\n",
    "        \n",
    "        for i, step in enumerate(response.steps, 1):\n",
    "            print(f\"  Step {step.number}: {step.name} [{step.key}]\")\n",
    "            \n",
    "            if step.key == \"modify_query\":\n",
    "                print(f\"    âœ æ”¹å†™: {step.prompt[:60]}...\")\n",
    "            elif step.key == \"query_entity_recognition\":\n",
    "                print(f\"    âœ å®ä½“è¯†åˆ«: {step.prompt[:60]}...\")\n",
    "            elif step.key == \"semantic_search_faq\":\n",
    "                print(f\"    âœ FAQæœç´¢: {step.prompt}\")\n",
    "                if \"æœªæ‰¾åˆ°\" in str(step.prompt) or \"ç›¸ä¼¼åº¦\" in str(step.prompt):\n",
    "                    if \"0.7\" not in str(step.prompt) or float(str(step.prompt).split(\"ï¼š\")[-1]) < 0.7:\n",
    "                        print(f\"       âœ“ FAQç›¸ä¼¼åº¦ä½äº0.7ï¼Œä¸ä½œä¸ºå‚è€ƒ\")\n",
    "            elif step.key == \"locate_table\":\n",
    "                if isinstance(step.prompt, list):\n",
    "                    print(f\"    âœ å®šä½åˆ° {len(step.prompt)} ä¸ªç›¸å…³è¡¨\")\n",
    "            elif step.key == \"generate_prompt\":\n",
    "                prompt_str = str(step.prompt)\n",
    "                if \"å‚è€ƒç¤ºä¾‹\" in prompt_str:\n",
    "                    has_faq_reference = True\n",
    "                    print(f\"    âœ æç¤ºè¯åŒ…å«FAQå‚è€ƒ\")\n",
    "                else:\n",
    "                    print(f\"    âœ æç¤ºè¯æœªåŒ…å«FAQå‚è€ƒï¼ˆç›¸ä¼¼åº¦è¿‡ä½ï¼‰\")\n",
    "            elif step.key == \"generate_sql\":\n",
    "                print(f\"    âœ LLMç”ŸæˆSQLå®Œæˆ\")\n",
    "        \n",
    "        # å±•ç¤ºæœ€ç»ˆSQLè¾“å‡º\n",
    "        print(\"\\nğŸ’ æœ€ç»ˆSQLè¾“å‡º:\")\n",
    "        if response.choices:\n",
    "            content = response.choices[0].message.content\n",
    "            # æå–å¹¶æ˜¾ç¤ºSQL\n",
    "            print(\"  \" + \"-\" * 76)\n",
    "            if \"SELECT\" in content.upper():\n",
    "                # ç®€å•å±•ç¤ºåŒ…å«SELECTçš„éƒ¨åˆ†\n",
    "                lines = content.split('\\n')\n",
    "                sql_lines = [line for line in lines if 'SELECT' in line.upper() or 'FROM' in line.upper() \n",
    "                            or 'WHERE' in line.upper() or 'GROUP' in line.upper()]\n",
    "                for line in sql_lines[:5]:\n",
    "                    print(f\"  {line.strip()}\")\n",
    "            else:\n",
    "                print(f\"  {content[:200]}...\")\n",
    "            print(\"  \" + \"-\" * 76)\n",
    "        \n",
    "        # éªŒè¯è·¯å¾„\n",
    "        print(\"\\nâœ… éªŒè¯ç»“æœ:\")\n",
    "        if len(response.steps) == 6 and not has_faq_reference:\n",
    "            print(\"  âœ“ ä½ç›¸ä¼¼åº¦å®Œæ•´è·¯å¾„éªŒè¯æˆåŠŸï¼\")\n",
    "            print(\"  âœ“ æ‰§è¡Œæ­¥éª¤æ•°: 6 (å®Œæ•´æµç¨‹)\")\n",
    "            print(\"  âœ“ FAQç›¸ä¼¼åº¦è¿‡ä½ï¼Œæœªä½œä¸ºå‚è€ƒ\")\n",
    "            print(\"  âœ“ çº¯ç²¹é€šè¿‡è¡¨æ ¼å®šä½å’ŒLLMç”ŸæˆSQL\")\n",
    "        else:\n",
    "            print(f\"  âš ï¸ éªŒè¯éœ€è¦ç¡®è®¤ï¼Œæ­¥éª¤æ•°: {len(response.steps)}\")\n",
    "            \n",
    "        return response\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ é”™è¯¯: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# æ‰§è¡Œæµ‹è¯•\n",
    "low_sim_response = test_e2e_low_similarity()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c210173",
   "metadata": {},
   "source": [
    "Cell 10: ç«¯åˆ°ç«¯æµ‹è¯• - è¿½é—®è·¯å¾„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e57148",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def test_e2e_follow_up():\n",
    "    \"\"\"\n",
    "    ç«¯åˆ°ç«¯æµ‹è¯•ï¼šè¿½é—®è·¯å¾„\n",
    "    User Query(ä¸å……åˆ†) -> è¿½é—® -> Userè¡¥å…… -> Step1-6 -> SQL Output\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"â“ ç«¯åˆ°ç«¯æµ‹è¯•ï¼šè¿½é—®è·¯å¾„\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # ç¬¬ä¸€è½®ï¼šä¿¡æ¯ä¸å……åˆ†çš„æŸ¥è¯¢\n",
    "    user_query_1 = \"æŸ¥è¯¢æˆäº¤é‡\"\n",
    "    print(f\"ğŸ“ ç¬¬1è½®ç”¨æˆ·æŸ¥è¯¢: {user_query_1}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    messages = [ChatMessage(role=\"user\", content=user_query_1)]\n",
    "    request_1 = DataQACompletionRequest(\n",
    "        messages=messages,\n",
    "        model=\"test\",\n",
    "        created=int(datetime.now().timestamp()),\n",
    "        follow_up_num=0\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        print(\"âš™ï¸ ç¬¬1è½®æ‰§è¡Œ...\")\n",
    "        response_1 = workflow.do_generate(\n",
    "            request=request_1,\n",
    "            enable_follow_up=True,\n",
    "            thinking=False\n",
    "        )\n",
    "        \n",
    "        # æ£€æŸ¥æ˜¯å¦è§¦å‘è¿½é—®\n",
    "        if response_1.choices[0].message.is_follow_up:\n",
    "            print(f\"âœ… è§¦å‘è¿½é—®: {response_1.choices[0].message.content}\")\n",
    "            print(\"\\n\" + \"-\" * 80)\n",
    "            \n",
    "            # ç¬¬äºŒè½®ï¼šç”¨æˆ·è¡¥å……ä¿¡æ¯\n",
    "            user_query_2 = \"æŸ¥è¯¢æ£‰èŠ±CFå“ç§2025å¹´7æœˆ2æ—¥çš„æˆäº¤é‡\"\n",
    "            print(f\"\\nğŸ“ ç¬¬2è½®ç”¨æˆ·è¡¥å……: {user_query_2}\")\n",
    "            print(\"-\" * 80)\n",
    "            \n",
    "            # æ·»åŠ å†å²å¯¹è¯\n",
    "            messages.append(response_1.choices[0].message)\n",
    "            messages.append(ChatMessage(role=\"user\", content=user_query_2))\n",
    "            \n",
    "            request_2 = DataQACompletionRequest(\n",
    "                messages=messages,\n",
    "                model=\"test\",\n",
    "                created=int(datetime.now().timestamp()),\n",
    "                follow_up_num=1\n",
    "            )\n",
    "            \n",
    "            print(\"âš™ï¸ ç¬¬2è½®æ‰§è¡Œ...\")\n",
    "            response_2 = workflow.do_generate(\n",
    "                request=request_2,\n",
    "                enable_follow_up=True,\n",
    "                thinking=False\n",
    "            )\n",
    "            \n",
    "            # å±•ç¤ºå®Œæ•´æ‰§è¡Œè·¯å¾„\n",
    "            print(\"\\nğŸ“Š æœ€ç»ˆæ‰§è¡Œè·¯å¾„:\")\n",
    "            for step in response_2.steps:\n",
    "                print(f\"  Step {step.number}: {step.name} [{step.key}]\")\n",
    "                if step.key == \"modify_query\":\n",
    "                    print(f\"    âœ æ•´åˆåæŸ¥è¯¢: {step.prompt[:60]}...\")\n",
    "            \n",
    "            # å±•ç¤ºæœ€ç»ˆSQL\n",
    "            print(\"\\nğŸ’ æœ€ç»ˆSQLè¾“å‡º:\")\n",
    "            if response_2.choices:\n",
    "                content = response_2.choices[0].message.content\n",
    "                print(\"  \" + \"-\" * 76)\n",
    "                # å±•ç¤ºSQLç›¸å…³å†…å®¹\n",
    "                lines = content.split('\\n')\n",
    "                for line in lines[:10]:\n",
    "                    if any(keyword in line.upper() for keyword in ['SELECT', 'FROM', 'WHERE']):\n",
    "                        print(f\"  {line.strip()}\")\n",
    "                print(\"  \" + \"-\" * 76)\n",
    "            \n",
    "            print(\"\\nâœ… éªŒè¯ç»“æœ:\")\n",
    "            print(\"  âœ“ è¿½é—®æµç¨‹éªŒè¯æˆåŠŸï¼\")\n",
    "            print(f\"  âœ“ ç¬¬1è½®ï¼šè§¦å‘è¿½é—®ï¼ˆä¿¡æ¯ä¸è¶³ï¼‰\")\n",
    "            print(f\"  âœ“ ç¬¬2è½®ï¼šæ‰§è¡Œå®Œæ•´æŸ¥è¯¢ï¼ˆ{len(response_2.steps)}ä¸ªæ­¥éª¤ï¼‰\")\n",
    "            print(\"  âœ“ æœ€ç»ˆç”ŸæˆSQL\")\n",
    "            \n",
    "            return response_2\n",
    "        else:\n",
    "            print(\"âš ï¸ æœªè§¦å‘è¿½é—®ï¼Œå¯èƒ½æŸ¥è¯¢è¢«ä¼˜åŒ–å™¨è¡¥å……äº†ä¿¡æ¯\")\n",
    "            return response_1\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ é”™è¯¯: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# æ‰§è¡Œæµ‹è¯•\n",
    "follow_up_response = test_e2e_follow_up()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8737a79f",
   "metadata": {},
   "source": [
    "Cell 11: ç«¯åˆ°ç«¯æµ‹è¯• - Thinkingæ¨¡å¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbd08ae",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def test_e2e_thinking_mode():\n",
    "    \"\"\"\n",
    "    ç«¯åˆ°ç«¯æµ‹è¯•ï¼šThinkingæ¨¡å¼å¯¹æ¯”\n",
    "    åŒä¸€æŸ¥è¯¢åˆ†åˆ«ç”¨æ™®é€šæ¨¡å¼å’ŒThinkingæ¨¡å¼æ‰§è¡Œ\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"ğŸ§  ç«¯åˆ°ç«¯æµ‹è¯•ï¼šThinkingæ¨¡å¼å¯¹æ¯”\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # ä½¿ç”¨ä¸€ä¸ªå¤æ‚æŸ¥è¯¢\n",
    "    user_query = \"åˆ†ææ£‰èŠ±æœŸè´§CFå“ç§æœ€è¿‘7å¤©çš„ä»·æ ¼èµ°åŠ¿ï¼Œè®¡ç®—æ—¥å‡æˆäº¤é‡å’Œæ³¢åŠ¨ç‡\"\n",
    "    print(f\"ğŸ“ ç”¨æˆ·æŸ¥è¯¢: {user_query}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    messages = [ChatMessage(role=\"user\", content=user_query)]\n",
    "    request = DataQACompletionRequest(\n",
    "        messages=messages,\n",
    "        model=\"test\",\n",
    "        created=int(datetime.now().timestamp()),\n",
    "        follow_up_num=0\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # 1. æ™®é€šæ¨¡å¼\n",
    "        print(\"\\nğŸ”¹ æ™®é€šæ¨¡å¼æ‰§è¡Œ:\")\n",
    "        print(\"âš™ï¸ æ‰§è¡Œdo_generateå‡½æ•°...\")\n",
    "        response_normal = workflow.do_generate(\n",
    "            request=request,\n",
    "            enable_follow_up=False,\n",
    "            thinking=False\n",
    "        )\n",
    "        \n",
    "        print(\"  æ‰§è¡Œæ­¥éª¤:\")\n",
    "        for step in response_normal.steps:\n",
    "            print(f\"    - {step.name}\")\n",
    "        print(f\"  Tokenä½¿ç”¨: {response_normal.usage.total_tokens}\")\n",
    "        \n",
    "        # 2. Thinkingæ¨¡å¼\n",
    "        print(\"\\nğŸ”¹ Thinkingæ¨¡å¼æ‰§è¡Œ:\")\n",
    "        print(\"âš™ï¸ æ‰§è¡Œdo_generateå‡½æ•°...\")\n",
    "        response_thinking = workflow.do_generate(\n",
    "            request=request,\n",
    "            enable_follow_up=False,\n",
    "            thinking=True\n",
    "        )\n",
    "        \n",
    "        print(\"  æ‰§è¡Œæ­¥éª¤:\")\n",
    "        for step in response_thinking.steps:\n",
    "            print(f\"    - {step.name}\")\n",
    "        print(f\"  Tokenä½¿ç”¨: {response_thinking.usage.total_tokens}\")\n",
    "        \n",
    "        # å±•ç¤ºSQLå¯¹æ¯”\n",
    "        print(\"\\nğŸ’ SQLè¾“å‡ºå¯¹æ¯”:\")\n",
    "        \n",
    "        print(\"\\næ™®é€šæ¨¡å¼SQL:\")\n",
    "        print(\"  \" + \"-\" * 76)\n",
    "        if response_normal.choices:\n",
    "            content_normal = response_normal.choices[0].message.content\n",
    "            # æå–SQLå±•ç¤º\n",
    "            if \"SELECT\" in content_normal.upper():\n",
    "                lines = content_normal.split('\\n')\n",
    "                for line in lines[:5]:\n",
    "                    if any(kw in line.upper() for kw in ['SELECT', 'FROM', 'WHERE', 'GROUP', 'ORDER']):\n",
    "                        print(f\"  {line.strip()}\")\n",
    "        print(\"  \" + \"-\" * 76)\n",
    "        \n",
    "        print(\"\\nThinkingæ¨¡å¼SQL:\")\n",
    "        print(\"  \" + \"-\" * 76)\n",
    "        if response_thinking.choices:\n",
    "            content_thinking = response_thinking.choices[0].message.content\n",
    "            # æ£€æŸ¥reasoningå†…å®¹\n",
    "            if response_thinking.choices[0].message.reasoning_content:\n",
    "                print(f\"  [åŒ…å«æ¨ç†è¿‡ç¨‹ï¼Œé•¿åº¦: {len(response_thinking.choices[0].message.reasoning_content)}]\")\n",
    "            # æå–SQLå±•ç¤º\n",
    "            if \"SELECT\" in content_thinking.upper():\n",
    "                lines = content_thinking.split('\\n')\n",
    "                for line in lines[:5]:\n",
    "                    if any(kw in line.upper() for kw in ['SELECT', 'FROM', 'WHERE', 'GROUP', 'ORDER']):\n",
    "                        print(f\"  {line.strip()}\")\n",
    "        print(\"  \" + \"-\" * 76)\n",
    "        \n",
    "        # éªŒè¯å¯¹æ¯”\n",
    "        print(\"\\nâœ… éªŒè¯ç»“æœ:\")\n",
    "        token_diff = response_thinking.usage.total_tokens - response_normal.usage.total_tokens\n",
    "        print(f\"  âœ“ ä¸¤ç§æ¨¡å¼éƒ½æˆåŠŸç”ŸæˆSQL\")\n",
    "        print(f\"  âœ“ Thinkingæ¨¡å¼å¤šä½¿ç”¨ {token_diff} ä¸ªtokens\")\n",
    "        if response_thinking.choices[0].message.reasoning_content:\n",
    "            print(f\"  âœ“ Thinkingæ¨¡å¼åŒ…å«æ¨ç†å†…å®¹\")\n",
    "        print(f\"  âœ“ æ­¥éª¤æ•°ç›¸åŒ: {len(response_normal.steps)} ä¸ª\")\n",
    "        \n",
    "        return response_thinking\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ é”™è¯¯: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# æ‰§è¡Œæµ‹è¯•\n",
    "thinking_response = test_e2e_thinking_mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80d245d",
   "metadata": {},
   "source": [
    "Cell 12: ç»¼åˆæµ‹è¯•æ€»ç»“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf328c7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def test_e2e_comprehensive_summary():\n",
    "    \"\"\"\n",
    "    ç»¼åˆæµ‹è¯•æ€»ç»“ï¼šæ±‡æ€»æ‰€æœ‰ç«¯åˆ°ç«¯æµ‹è¯•ç»“æœ\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"ğŸ“Š ç«¯åˆ°ç«¯æµ‹è¯•ç»¼åˆæ€»ç»“\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # å®šä¹‰æµ‹è¯•åœºæ™¯å’Œå¯¹åº”çš„æŸ¥è¯¢\n",
    "    test_scenarios = {\n",
    "        \"é«˜ç›¸ä¼¼åº¦(>=0.85)\": {\n",
    "            \"queries\": [\n",
    "                \"æŸ¥è¯¢éƒ‘å•†æ‰€å½“å‰ä¸»åŠ›åˆçº¦çš„ä»£ç ã€ç»“ç®—ä»·åŠæˆäº¤é‡\",\n",
    "                \"ç­›é€‰å½“å‰ä¸»åŠ›åˆçº¦ç»“ç®—ä»·è¶…è¿‡2000å…ƒ/å¨çš„å“ç§\"\n",
    "            ],\n",
    "            \"expected_steps\": 3,\n",
    "            \"expected_path\": \"Step1â†’Step2â†’Step3(FAQç›´æ¥è¿”å›)\"\n",
    "        },\n",
    "        \"ä¸­ç­‰ç›¸ä¼¼åº¦(0.7-0.85)\": {\n",
    "            \"queries\": [\n",
    "                \"æŸ¥è¯¢éƒ‘å•†æ‰€ä¸»åŠ›åˆçº¦çš„ä»·æ ¼ä¿¡æ¯\",\n",
    "                \"ä¸»åŠ›åˆçº¦ç»“ç®—ä»·å¤§äº2000çš„å“ç§æœ‰å“ªäº›\"\n",
    "            ],\n",
    "            \"expected_steps\": 6,\n",
    "            \"expected_path\": \"Step1â†’Step2â†’Step3â†’Step4â†’Step5(FAQå‚è€ƒ)â†’Step6\"\n",
    "        },\n",
    "        \"ä½ç›¸ä¼¼åº¦(<0.7)\": {\n",
    "            \"queries\": [\n",
    "                \"ç»Ÿè®¡ä¸Šä¸ªæœˆçš„æœŸè´§äº¤æ˜“æ€»é¢\",\n",
    "                \"è®¡ç®—æ‰€æœ‰äº¤æ˜“æ‰€çš„å¹³å‡æ‰‹ç»­è´¹\"\n",
    "            ],\n",
    "            \"expected_steps\": 6,\n",
    "            \"expected_path\": \"Step1â†’Step2â†’Step3â†’Step4â†’Step5â†’Step6\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # æ‰§è¡Œæµ‹è¯•å¹¶æ”¶é›†ç»“æœ\n",
    "    test_results = []\n",
    "    \n",
    "    for scenario_name, scenario_config in test_scenarios.items():\n",
    "        print(f\"\\nğŸ”¹ æµ‹è¯•åœºæ™¯: {scenario_name}\")\n",
    "        print(f\"   é¢„æœŸæ­¥éª¤æ•°: {scenario_config['expected_steps']}\")\n",
    "        print(f\"   é¢„æœŸè·¯å¾„: {scenario_config['expected_path']}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        for query in scenario_config['queries'][:1]:  # æ¯ä¸ªåœºæ™¯æµ‹è¯•1ä¸ªæŸ¥è¯¢\n",
    "            print(f\"   æŸ¥è¯¢: {query[:50]}...\")\n",
    "            \n",
    "            try:\n",
    "                request = DataQACompletionRequest(\n",
    "                    messages=[ChatMessage(role=\"user\", content=query)],\n",
    "                    model=\"test\",\n",
    "                    created=int(datetime.now().timestamp()),\n",
    "                    follow_up_num=0\n",
    "                )\n",
    "                \n",
    "                response = workflow.do_generate(\n",
    "                    request=request,\n",
    "                    enable_follow_up=False,\n",
    "                    thinking=False\n",
    "                )\n",
    "                \n",
    "                # æ£€æŸ¥ç»“æœ\n",
    "                actual_steps = len(response.steps)\n",
    "                has_sql = False\n",
    "                \n",
    "                if response.choices:\n",
    "                    content = response.choices[0].message.content\n",
    "                    has_sql = \"SELECT\" in content.upper() or \"sql\" in content.lower()\n",
    "                \n",
    "                # è®°å½•ç»“æœ\n",
    "                result = {\n",
    "                    \"scenario\": scenario_name,\n",
    "                    \"query\": query[:50],\n",
    "                    \"expected_steps\": scenario_config['expected_steps'],\n",
    "                    \"actual_steps\": actual_steps,\n",
    "                    \"steps_match\": actual_steps == scenario_config['expected_steps'],\n",
    "                    \"has_sql\": has_sql,\n",
    "                    \"success\": actual_steps == scenario_config['expected_steps'] and has_sql\n",
    "                }\n",
    "                \n",
    "                test_results.append(result)\n",
    "                \n",
    "                # æ‰“å°ç»“æœ\n",
    "                status = \"âœ…\" if result['success'] else \"âš ï¸\"\n",
    "                print(f\"   {status} æ­¥éª¤æ•°: {actual_steps}/{scenario_config['expected_steps']}, SQLç”Ÿæˆ: {has_sql}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   âŒ é”™è¯¯: {str(e)[:50]}\")\n",
    "                test_results.append({\n",
    "                    \"scenario\": scenario_name,\n",
    "                    \"query\": query[:50],\n",
    "                    \"success\": False,\n",
    "                    \"error\": str(e)\n",
    "                })\n",
    "    \n",
    "    # æ±‡æ€»ç»Ÿè®¡\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ğŸ“ˆ æµ‹è¯•ç»Ÿè®¡\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    total_tests = len(test_results)\n",
    "    successful_tests = sum(1 for r in test_results if r.get('success', False))\n",
    "    \n",
    "    print(f\"æ€»æµ‹è¯•æ•°: {total_tests}\")\n",
    "    print(f\"æˆåŠŸæ•°: {successful_tests}\")\n",
    "    print(f\"æˆåŠŸç‡: {successful_tests/total_tests*100:.1f}%\")\n",
    "    \n",
    "    # åˆ†åœºæ™¯ç»Ÿè®¡\n",
    "    print(\"\\nåˆ†åœºæ™¯ç»Ÿè®¡:\")\n",
    "    for scenario in test_scenarios.keys():\n",
    "        scenario_results = [r for r in test_results if r['scenario'] == scenario]\n",
    "        scenario_success = sum(1 for r in scenario_results if r.get('success', False))\n",
    "        print(f\"  {scenario}: {scenario_success}/{len(scenario_results)} æˆåŠŸ\")\n",
    "    \n",
    "    print(\"\\nâœ… ç«¯åˆ°ç«¯æµ‹è¯•å®Œæˆ!\")\n",
    "    print(\"æ‰€æœ‰æ­¥éª¤éªŒè¯:\")\n",
    "    print(\"  âœ“ Step1: modify_query (é—®é¢˜æ”¹å†™)\")\n",
    "    print(\"  âœ“ Step2: entity_recognition (å®ä½“è¯†åˆ«)\")\n",
    "    print(\"  âœ“ Step3: semantic_search_faq (FAQè¯­ä¹‰æœç´¢)\")\n",
    "    print(\"  âœ“ Step4: locate_table (è¡¨æ ¼å®šä½)\")\n",
    "    print(\"  âœ“ Step5: generate_single_table_prompt (ç”Ÿæˆæç¤ºè¯)\")\n",
    "    print(\"  âœ“ Step6: generate_sql (ç”ŸæˆSQL)\")\n",
    "    \n",
    "    return test_results\n",
    "\n",
    "# æ‰§è¡Œç»¼åˆæµ‹è¯•\n",
    "final_results = test_e2e_comprehensive_summary()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
